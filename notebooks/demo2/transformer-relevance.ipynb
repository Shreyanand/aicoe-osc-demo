{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e7290c-5fac-4577-b45c-a992d2781307",
   "metadata": {},
   "source": [
    "## Hugging face relevance model\n",
    "\n",
    "This notebook first tries zero short learning with a bert model or in other words, direct prediction with a bert model on the climate relevance task. Then it fine tunes the bert model for the relevance task using the huggingface transformers package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa31f6-f3cc-4f06-803a-d4f9ef164eef",
   "metadata": {
    "papermill": {
     "duration": 3.30074,
     "end_time": "2022-10-07T19:33:18.885511",
     "exception": false,
     "start_time": "2022-10-07T19:33:15.584771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import config\n",
    "import os\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "from statistics import median\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from src.data.s3_communication import S3Communication\n",
    "from sparsezoo import Model\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import evaluate\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import random\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, pipeline\n",
    "from transformers import AutoTokenizer\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32c63a-7193-4c8f-87c4-93895d1b0e5e",
   "metadata": {
    "papermill": {
     "duration": 0.011639,
     "end_time": "2022-10-07T19:33:18.901426",
     "exception": false,
     "start_time": "2022-10-07T19:33:18.889787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd7c74-9873-4915-bed8-8b53dcdefc34",
   "metadata": {
    "papermill": {
     "duration": 0.090141,
     "end_time": "2022-10-07T19:33:18.997018",
     "exception": false,
     "start_time": "2022-10-07T19:33:18.906877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea123c-6728-4641-9afd-ebcdb66cc67b",
   "metadata": {
    "papermill": {
     "duration": 0.003808,
     "end_time": "2022-10-07T19:33:19.004776",
     "exception": false,
     "start_time": "2022-10-07T19:33:19.000968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Retrieve the test dataset and the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a228ca9-2e0e-4aed-940d-25719c7db9d3",
   "metadata": {
    "papermill": {
     "duration": 0.886377,
     "end_time": "2022-10-07T19:33:19.895045",
     "exception": false,
     "start_time": "2022-10-07T19:33:19.008668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3c.download_files_in_prefix_to_dir(\n",
    "    config.BASE_TRAIN_TEST_DATASET_S3_PREFIX,\n",
    "    config.BASE_PROCESSED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb79a109-8f79-4a87-ac7d-7880abe277ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = str(config.BASE_PROCESSED_DATA)+'/rel_test_split.csv'\n",
    "test_data = pd.read_csv(test_data_path, index_col=0)\n",
    "test_data.rename(columns={'text':'question', 'text_b':'sentence'}, inplace=True)\n",
    "\n",
    "train_data_path = str(config.BASE_PROCESSED_DATA)+'/rel_train_split.csv'\n",
    "train_data = pd.read_csv(train_data_path, index_col=0)\n",
    "train_data.rename(columns={'text':'question', 'text_b':'sentence'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecdf4bda-0d05-47b8-8f70-17383e86c76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>question</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the annual total production from ligni...</td>\n",
       "      <td>PJM's Operating ORDC Filing — On March 29, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the annual total production from ligni...</td>\n",
       "      <td>64.8 million metric tons of lignite produced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           question  \\\n",
       "403      0  What is the annual total production from ligni...   \n",
       "402      1  What is the annual total production from ligni...   \n",
       "\n",
       "                                              sentence  \n",
       "403  PJM's Operating ORDC Filing — On March 29, 201...  \n",
       "402      64.8 million metric tons of lignite produced   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['question']=='What is the annual total production from lignite (brown coal)?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1643cf4f-03e6-4835-a621-0533274419a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trds = Dataset.from_pandas(train_data)\n",
    "teds = Dataset.from_pandas(test_data.drop('label', axis=1))\n",
    "\n",
    "climate_dataset = DatasetDict()\n",
    "\n",
    "climate_dataset['train'] = trds\n",
    "climate_dataset['test'] = teds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55ac325-187b-4335-994d-cc89506c887e",
   "metadata": {},
   "source": [
    "# Try zero shot learning or directly inferencing with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79f121-4703-4fcf-98f9-9307c728a072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "sequences = (test_data['question'] + ' [SEP] ' + test_data['sentence']).values.tolist()\n",
    "classifier = pipeline(task='zero-shot-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d1819c-35b2-4d6a-ab8c-0931337a16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(sequences, size=10):\n",
    "    batches = list()\n",
    "    i=0\n",
    "    while i < len(sequences):\n",
    "        end = i+size\n",
    "        if end > len(sequences):\n",
    "            end = len(sequences)\n",
    "        batches.append(sequences[i:end])\n",
    "        i+=size\n",
    "    return batches\n",
    "\n",
    "\n",
    "batches = make_batches(sequences, size=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "147d0a39-67a0-404f-a0e4-148ce03456c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list()\n",
    "for batch in batches:\n",
    "    results.extend(classifier(batch, [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99826d72-2678-4649-bd70-00a80bf0a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = [results[i]['scores'][0] for i in range(509)]\n",
    "cutoff = median(label_1)\n",
    "pred = list()\n",
    "for label in label_1:\n",
    "    pred.append(1 if label > cutoff else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "419d8578-3579-4df4-9470-aaaed4a45ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"pred\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62c74108-5e89-4469-b278-736bc55e9cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#evalute performance\n",
    "groups = test_data.groupby(\"question\")\n",
    "scores = {}\n",
    "for group, data in groups:\n",
    "    pred = data.pred\n",
    "    true = data.label\n",
    "    scores[group] = {}\n",
    "    scores[group][\"accuracy\"] = accuracy_score(true, pred)\n",
    "    scores[group][\"f1_score\"] = f1_score(true, pred)\n",
    "    scores[group][\"recall_score\"] = recall_score(true, pred)\n",
    "    scores[group][\"precision_score\"] = precision_score(true, pred)\n",
    "    scores[group][\"support\"] = len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ce881dd-77a7-40af-9b48-61a6c5db25eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>In which year was the annual report or the sustainability report published?</th>\n",
       "      <th>What is the annual total production from coal?</th>\n",
       "      <th>What is the base year for carbon reduction commitment?</th>\n",
       "      <th>What is the climate commitment scenario considered?</th>\n",
       "      <th>What is the company name?</th>\n",
       "      <th>What is the target carbon reduction in percentage?</th>\n",
       "      <th>What is the target year for climate commitment?</th>\n",
       "      <th>What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?</th>\n",
       "      <th>What is the total amount of energy indirect greenhouse gases emissions referred to as scope 2 emissions?</th>\n",
       "      <th>What is the total amount of scope 1 and 2 greenhouse gases emissions?</th>\n",
       "      <th>...</th>\n",
       "      <th>What is the total amount of upstream energy indirect greenhouse gases emissions referred to as scope 3 emissions?</th>\n",
       "      <th>What is the total installed capacity from coal?</th>\n",
       "      <th>What is the total installed capacity from lignite (brown coal)?</th>\n",
       "      <th>What is the total volume of crude oil liquid production?</th>\n",
       "      <th>What is the total volume of hydrocarbons production?</th>\n",
       "      <th>What is the total volume of natural gas liquid production?</th>\n",
       "      <th>What is the total volume of natural gas production?</th>\n",
       "      <th>What is the total volume of proven and probable hydrocarbons reserves?</th>\n",
       "      <th>What is the volume of estimated probable hydrocarbons reserves?</th>\n",
       "      <th>What is the volume of estimated proven hydrocarbons reserves?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score</th>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 In which year was the annual report or the sustainability report published?  \\\n",
       "accuracy                                                  0.695652                             \n",
       "f1_score                                                  0.666667                             \n",
       "recall_score                                              0.717949                             \n",
       "precision_score                                           0.622222                             \n",
       "support                                                  92.000000                             \n",
       "\n",
       "                 What is the annual total production from coal?  \\\n",
       "accuracy                                               0.166667   \n",
       "f1_score                                               0.285714   \n",
       "recall_score                                           0.250000   \n",
       "precision_score                                        0.333333   \n",
       "support                                                6.000000   \n",
       "\n",
       "                 What is the base year for carbon reduction commitment?  \\\n",
       "accuracy                                                  0.320000        \n",
       "f1_score                                                  0.260870        \n",
       "recall_score                                              0.250000        \n",
       "precision_score                                           0.272727        \n",
       "support                                                  25.000000        \n",
       "\n",
       "                 What is the climate commitment scenario considered?  \\\n",
       "accuracy                                                  0.520000     \n",
       "f1_score                                                  0.250000     \n",
       "recall_score                                              0.181818     \n",
       "precision_score                                           0.400000     \n",
       "support                                                  25.000000     \n",
       "\n",
       "                 What is the company name?  \\\n",
       "accuracy                          0.603774   \n",
       "f1_score                          0.571429   \n",
       "recall_score                      0.700000   \n",
       "precision_score                   0.482759   \n",
       "support                          53.000000   \n",
       "\n",
       "                 What is the target carbon reduction in percentage?  \\\n",
       "accuracy                                                  0.470588    \n",
       "f1_score                                                  0.526316    \n",
       "recall_score                                              0.833333    \n",
       "precision_score                                           0.384615    \n",
       "support                                                  34.000000    \n",
       "\n",
       "                 What is the target year for climate commitment?  \\\n",
       "accuracy                                                0.608696   \n",
       "f1_score                                                0.357143   \n",
       "recall_score                                            0.250000   \n",
       "precision_score                                         0.625000   \n",
       "support                                                46.000000   \n",
       "\n",
       "                 What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?  \\\n",
       "accuracy                                                  0.555556                                                 \n",
       "f1_score                                                  0.692308                                                 \n",
       "recall_score                                              1.000000                                                 \n",
       "precision_score                                           0.529412                                                 \n",
       "support                                                  18.000000                                                 \n",
       "\n",
       "                 What is the total amount of energy indirect greenhouse gases emissions referred to as scope 2 emissions?  \\\n",
       "accuracy                                                  0.538462                                                          \n",
       "f1_score                                                  0.000000                                                          \n",
       "recall_score                                              0.000000                                                          \n",
       "precision_score                                           0.000000                                                          \n",
       "support                                                  13.000000                                                          \n",
       "\n",
       "                 What is the total amount of scope 1 and 2 greenhouse gases emissions?  \\\n",
       "accuracy                                                       0.0                       \n",
       "f1_score                                                       0.0                       \n",
       "recall_score                                                   0.0                       \n",
       "precision_score                                                0.0                       \n",
       "support                                                        2.0                       \n",
       "\n",
       "                 ...  \\\n",
       "accuracy         ...   \n",
       "f1_score         ...   \n",
       "recall_score     ...   \n",
       "precision_score  ...   \n",
       "support          ...   \n",
       "\n",
       "                 What is the total amount of upstream energy indirect greenhouse gases emissions referred to as scope 3 emissions?  \\\n",
       "accuracy                                                  0.466667                                                                   \n",
       "f1_score                                                  0.000000                                                                   \n",
       "recall_score                                              0.000000                                                                   \n",
       "precision_score                                           0.000000                                                                   \n",
       "support                                                  15.000000                                                                   \n",
       "\n",
       "                 What is the total installed capacity from coal?  \\\n",
       "accuracy                                                0.500000   \n",
       "f1_score                                                0.500000   \n",
       "recall_score                                            0.333333   \n",
       "precision_score                                         1.000000   \n",
       "support                                                 4.000000   \n",
       "\n",
       "                 What is the total installed capacity from lignite (brown coal)?  \\\n",
       "accuracy                                                       1.0                 \n",
       "f1_score                                                       0.0                 \n",
       "recall_score                                                   0.0                 \n",
       "precision_score                                                0.0                 \n",
       "support                                                        1.0                 \n",
       "\n",
       "                 What is the total volume of crude oil liquid production?  \\\n",
       "accuracy                                                  0.333333          \n",
       "f1_score                                                  0.000000          \n",
       "recall_score                                              0.000000          \n",
       "precision_score                                           0.000000          \n",
       "support                                                   3.000000          \n",
       "\n",
       "                 What is the total volume of hydrocarbons production?  \\\n",
       "accuracy                                                  0.371429      \n",
       "f1_score                                                  0.371429      \n",
       "recall_score                                              0.464286      \n",
       "precision_score                                           0.309524      \n",
       "support                                                  70.000000      \n",
       "\n",
       "                 What is the total volume of natural gas liquid production?  \\\n",
       "accuracy                                                       0.5            \n",
       "f1_score                                                       0.5            \n",
       "recall_score                                                   0.5            \n",
       "precision_score                                                0.5            \n",
       "support                                                        4.0            \n",
       "\n",
       "                 What is the total volume of natural gas production?  \\\n",
       "accuracy                                                  0.312500     \n",
       "f1_score                                                  0.352941     \n",
       "recall_score                                              0.600000     \n",
       "precision_score                                           0.250000     \n",
       "support                                                  16.000000     \n",
       "\n",
       "                 What is the total volume of proven and probable hydrocarbons reserves?  \\\n",
       "accuracy                                                  0.454545                        \n",
       "f1_score                                                  0.437500                        \n",
       "recall_score                                              0.411765                        \n",
       "precision_score                                           0.466667                        \n",
       "support                                                  33.000000                        \n",
       "\n",
       "                 What is the volume of estimated probable hydrocarbons reserves?  \\\n",
       "accuracy                                                       0.0                 \n",
       "f1_score                                                       0.0                 \n",
       "recall_score                                                   0.0                 \n",
       "precision_score                                                0.0                 \n",
       "support                                                        1.0                 \n",
       "\n",
       "                 What is the volume of estimated proven hydrocarbons reserves?  \n",
       "accuracy                                                  0.531915              \n",
       "f1_score                                                  0.592593              \n",
       "recall_score                                              0.727273              \n",
       "precision_score                                           0.500000              \n",
       "support                                                  47.000000              \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kpi wise performance metrics\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9acce399-c3d4-4890-818b-d34eeb842e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30309084611632864"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.loc['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e27a56-b710-4fca-8a73-482121dd82ee",
   "metadata": {},
   "source": [
    "That f1 score s*cks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee5f3e2-97e3-48d3-be09-28a7aa44f2e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using distil BERT model for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66bbfc5d-40dc-4064-8ae0-2d5ff4e7abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = str(config.BASE_PROCESSED_DATA)+'/rel_test_split.csv'\n",
    "test_data = pd.read_csv(test_data_path, index_col=0)\n",
    "test_data.rename(columns={'text':'question', 'text_b':'sentence'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85976d26-03e2-4003-89c6-0133a5788549",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"qnli\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8797a18-6913-48aa-84f8-7e58b9fadba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_task = \"qnli\"\n",
    "metric = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c193a9-50ef-4a36-b0be-a3911c0d2d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>question</th>\n",
       "      <th>sentence</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the base year for carbon reduction commitment?</td>\n",
       "      <td>The global challenge of climate change will dominate many debates in 2020 and the years ahead. Equinor`s joint statement with Climate Action 100+ from April 2019, forms the starting point for our investor dialogue in support of the goals of the Paris Agreement. In our updated climate roadmap, we recognise the need for significant changes in the energy markets, which means that also Equinor`s portfolio will have to change accordingly to remain competitive. We will produce less oil in a low carbon future, but value creation will still be high. Oil and gas production with low greenhouse gas emissions will be an even stronger competitive advantage for us. In addition, profitable growth in renewables gives significant new opportunities to create attractive returns.</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In which year was the annual report or the sustainability report published?</td>\n",
       "      <td>The new Industrial Plan gives impetus to growth through an integrated business model. The portfolio of conventional assets1, the high percentage of gas reserves and the development of renewable sources thanks to synergies with Eni’s industrial assets will favour the evolution of the business model towards a low-carbon scenario, also thanks to technological development and digitalization in support of asset integrity and operating efficiency. Moreover, in the Gas &amp; Power sector Eni will continue to restructure its procurement portfolio and re- duce logistics costs, also by increasing integration with other businesses including LNG and Trading. The Plan provides for the continued development of Green projects, including the start-up of the Gela green refinery plant and the expansion of the Venice plant, as well as the commitment to sustainable mobility through the increased supply of alternative fuels and the growth of enjoy2. Circular economy initiatives for waste transformation will also be developed; through these, Eni aims to reduce green- house gas emissions in production processes by increasing energy efficiency.</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>In which year was the annual report or the sustainability report published?</td>\n",
       "      <td>BP Sustainability Report 2019</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>In which year was the annual report or the sustainability report published?</td>\n",
       "      <td>Cabot Oil &amp; Gas Corporation 2019 Annual Report</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?</td>\n",
       "      <td>In 2018, direct emissions of CO2 equivalent (Scope 1) amounted to approximately 95 million equivalent tons, registering a decrease of 10% compared to 2017.</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the company name?</td>\n",
       "      <td>EmblaHod Deep WestEldﬁskEkoﬁskEddaVest ekoﬁskExploration prospect</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the total volume of hydrocarbons production?</td>\n",
       "      <td>Upstream plans to maintain production at around 110 mboepd in 2019 (and at 100-110 mboepd in 2019-23)</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the total volume of hydrocarbons production?</td>\n",
       "      <td>Hunting Dearborn is a world leader in the deep drilling of high grade, non-magnetic components. As a Group, Hunting has the ability to produce fully integrated advanced downhole tools and equipment, manufactured, assembled and tested to the customer’s specifications using its proprietary know-how.</td>\n",
       "      <td>1847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the total volume of natural gas production?</td>\n",
       "      <td>Galp is a member of the London Benchmarking Group and uses its methodology, which is an international benchmark to classify, manage, measure and communicate its contribution to society.</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the total volume of proven and probable hydrocarbons reserves?</td>\n",
       "      <td>FormoresegmentreportingandthereconciliationofthesefigureswiththeIFRS‐EUFinancialStatements,seeAppendix II.</td>\n",
       "      <td>2245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "\n",
    "show_random_elements(climate_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4926652-44d4-4cdb-aded-f274b8612b04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 1010, 2023, 2028, 6251, 999, 102, 1998, 2023, 6251, 3632, 2007, 2009, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "tokenizer(\"Hello, this one sentence!\", \"And this sentence goes with it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a599eb-6fda-4da3-8aa5-117e9f05c98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: What is the climate commitment scenario considered?\n",
      "Sentence 2: This is the motivation behind Enel's support for the initiatives undertaken by the countries in which it operates, aimed at achieving the objectives established in the Paris Agreement. The commitment to the SDGs was strengthened by setting targets through 2030, strengthening the objective of reducing specific CO2 emissions to 0.23 kg/kWheq (SDG 13) and increasing the level of interaction between the Group and local communities, fostering their access to education (SDG 4), energy (SDG 7) and employment as well as sustainable and inclusive economic growth (SDG 8).\n"
     ]
    }
   ],
   "source": [
    "task_to_keys = {\"qnli\": (\"question\", \"sentence\")}\n",
    "sentence1_key, sentence2_key = task_to_keys[actual_task]\n",
    "print(f\"Sentence 1: {climate_dataset['train'][0][sentence1_key]}\")\n",
    "print(f\"Sentence 2: {climate_dataset['train'][0][sentence2_key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a9a844b-75c0-4d99-a2f7-13aa51ca3f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971cde08e6a44de99f46b4da420458cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e1cc23f09f4429865f37ace6f16c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[sentence1_key],\n",
    "                     examples[sentence2_key],\n",
    "                     truncation=True)\n",
    "\n",
    "\n",
    "encoded_climate_dataset = climate_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b605ecb0-877c-47d6-96f8-95b8ca04a971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'distilbert-base-uncased'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = 2\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "metric_name=\"f1\"\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c379bf29-57a2-41be-8380-1cc19518261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"no\",\n",
    "    save_strategy = \"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=16,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37d3befc-d8bb-48f8-b681-186888708116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea0b3dd1-d07c-475a-b228-a1b46ae47dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, question. If __index_level_0__, sentence, question are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2033\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2048' max='2048' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2048/2048 03:58, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2048, training_loss=0.042531981715001166, metrics={'train_runtime': 241.1649, 'train_samples_per_second': 134.879, 'train_steps_per_second': 8.492, 'total_flos': 1815869827636536.0, 'train_loss': 0.042531981715001166, 'epoch': 16.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_climate_dataset[\"train\"],\n",
    "    eval_dataset=None,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e5b5005-a754-45ac-85ea-91d432c6b2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e5509289d24b3584b27b1298c29874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c5e839133b4b75958b7f8f03ab01ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "teds = Dataset.from_pandas(test_data)\n",
    "climate_dataset['test'] = teds\n",
    "encoded_climate_dataset_wl = climate_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbb57504-1337-42b7-8c58-0b0d444df5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence, question. If __index_level_0__, sentence, question are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 509\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(encoded_climate_dataset_wl['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06e99980-e464-4c81-958a-932f8157f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = np.argmax(pred.predictions, axis=1)\n",
    "test_data[\"pred\"]=label_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36f8c03b-54de-49b2-a842-4f27ffece625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>In which year was the annual report or the sustainability report published?</th>\n",
       "      <th>What is the annual total production from coal?</th>\n",
       "      <th>What is the base year for carbon reduction commitment?</th>\n",
       "      <th>What is the climate commitment scenario considered?</th>\n",
       "      <th>What is the company name?</th>\n",
       "      <th>What is the target carbon reduction in percentage?</th>\n",
       "      <th>What is the target year for climate commitment?</th>\n",
       "      <th>What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?</th>\n",
       "      <th>What is the total amount of energy indirect greenhouse gases emissions referred to as scope 2 emissions?</th>\n",
       "      <th>What is the total amount of scope 1 and 2 greenhouse gases emissions?</th>\n",
       "      <th>...</th>\n",
       "      <th>What is the total amount of upstream energy indirect greenhouse gases emissions referred to as scope 3 emissions?</th>\n",
       "      <th>What is the total installed capacity from coal?</th>\n",
       "      <th>What is the total installed capacity from lignite (brown coal)?</th>\n",
       "      <th>What is the total volume of crude oil liquid production?</th>\n",
       "      <th>What is the total volume of hydrocarbons production?</th>\n",
       "      <th>What is the total volume of natural gas liquid production?</th>\n",
       "      <th>What is the total volume of natural gas production?</th>\n",
       "      <th>What is the total volume of proven and probable hydrocarbons reserves?</th>\n",
       "      <th>What is the volume of estimated probable hydrocarbons reserves?</th>\n",
       "      <th>What is the volume of estimated proven hydrocarbons reserves?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.847826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.847826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score</th>\n",
       "      <td>0.735849</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 In which year was the annual report or the sustainability report published?  \\\n",
       "accuracy                                                  0.847826                             \n",
       "f1_score                                                  0.847826                             \n",
       "recall_score                                              1.000000                             \n",
       "precision_score                                           0.735849                             \n",
       "support                                                  92.000000                             \n",
       "\n",
       "                 What is the annual total production from coal?  \\\n",
       "accuracy                                                    1.0   \n",
       "f1_score                                                    1.0   \n",
       "recall_score                                                1.0   \n",
       "precision_score                                             1.0   \n",
       "support                                                     6.0   \n",
       "\n",
       "                 What is the base year for carbon reduction commitment?  \\\n",
       "accuracy                                                  0.960000        \n",
       "f1_score                                                  0.960000        \n",
       "recall_score                                              1.000000        \n",
       "precision_score                                           0.923077        \n",
       "support                                                  25.000000        \n",
       "\n",
       "                 What is the climate commitment scenario considered?  \\\n",
       "accuracy                                                  0.960000     \n",
       "f1_score                                                  0.952381     \n",
       "recall_score                                              0.909091     \n",
       "precision_score                                           1.000000     \n",
       "support                                                  25.000000     \n",
       "\n",
       "                 What is the company name?  \\\n",
       "accuracy                          0.886792   \n",
       "f1_score                          0.857143   \n",
       "recall_score                      0.900000   \n",
       "precision_score                   0.818182   \n",
       "support                          53.000000   \n",
       "\n",
       "                 What is the target carbon reduction in percentage?  \\\n",
       "accuracy                                                  0.970588    \n",
       "f1_score                                                  0.960000    \n",
       "recall_score                                              1.000000    \n",
       "precision_score                                           0.923077    \n",
       "support                                                  34.000000    \n",
       "\n",
       "                 What is the target year for climate commitment?  \\\n",
       "accuracy                                                0.956522   \n",
       "f1_score                                                0.952381   \n",
       "recall_score                                            1.000000   \n",
       "precision_score                                         0.909091   \n",
       "support                                                46.000000   \n",
       "\n",
       "                 What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?  \\\n",
       "accuracy                                                  0.944444                                                 \n",
       "f1_score                                                  0.947368                                                 \n",
       "recall_score                                              1.000000                                                 \n",
       "precision_score                                           0.900000                                                 \n",
       "support                                                  18.000000                                                 \n",
       "\n",
       "                 What is the total amount of energy indirect greenhouse gases emissions referred to as scope 2 emissions?  \\\n",
       "accuracy                                                       1.0                                                          \n",
       "f1_score                                                       1.0                                                          \n",
       "recall_score                                                   1.0                                                          \n",
       "precision_score                                                1.0                                                          \n",
       "support                                                       13.0                                                          \n",
       "\n",
       "                 What is the total amount of scope 1 and 2 greenhouse gases emissions?  \\\n",
       "accuracy                                                       1.0                       \n",
       "f1_score                                                       1.0                       \n",
       "recall_score                                                   1.0                       \n",
       "precision_score                                                1.0                       \n",
       "support                                                        2.0                       \n",
       "\n",
       "                 ...  \\\n",
       "accuracy         ...   \n",
       "f1_score         ...   \n",
       "recall_score     ...   \n",
       "precision_score  ...   \n",
       "support          ...   \n",
       "\n",
       "                 What is the total amount of upstream energy indirect greenhouse gases emissions referred to as scope 3 emissions?  \\\n",
       "accuracy                                                       1.0                                                                   \n",
       "f1_score                                                       1.0                                                                   \n",
       "recall_score                                                   1.0                                                                   \n",
       "precision_score                                                1.0                                                                   \n",
       "support                                                       15.0                                                                   \n",
       "\n",
       "                 What is the total installed capacity from coal?  \\\n",
       "accuracy                                                     1.0   \n",
       "f1_score                                                     1.0   \n",
       "recall_score                                                 1.0   \n",
       "precision_score                                              1.0   \n",
       "support                                                      4.0   \n",
       "\n",
       "                 What is the total installed capacity from lignite (brown coal)?  \\\n",
       "accuracy                                                       1.0                 \n",
       "f1_score                                                       0.0                 \n",
       "recall_score                                                   0.0                 \n",
       "precision_score                                                0.0                 \n",
       "support                                                        1.0                 \n",
       "\n",
       "                 What is the total volume of crude oil liquid production?  \\\n",
       "accuracy                                                       1.0          \n",
       "f1_score                                                       1.0          \n",
       "recall_score                                                   1.0          \n",
       "precision_score                                                1.0          \n",
       "support                                                        3.0          \n",
       "\n",
       "                 What is the total volume of hydrocarbons production?  \\\n",
       "accuracy                                                       1.0      \n",
       "f1_score                                                       1.0      \n",
       "recall_score                                                   1.0      \n",
       "precision_score                                                1.0      \n",
       "support                                                       70.0      \n",
       "\n",
       "                 What is the total volume of natural gas liquid production?  \\\n",
       "accuracy                                                  0.750000            \n",
       "f1_score                                                  0.800000            \n",
       "recall_score                                              1.000000            \n",
       "precision_score                                           0.666667            \n",
       "support                                                   4.000000            \n",
       "\n",
       "                 What is the total volume of natural gas production?  \\\n",
       "accuracy                                                       1.0     \n",
       "f1_score                                                       1.0     \n",
       "recall_score                                                   1.0     \n",
       "precision_score                                                1.0     \n",
       "support                                                       16.0     \n",
       "\n",
       "                 What is the total volume of proven and probable hydrocarbons reserves?  \\\n",
       "accuracy                                                       1.0                        \n",
       "f1_score                                                       1.0                        \n",
       "recall_score                                                   1.0                        \n",
       "precision_score                                                1.0                        \n",
       "support                                                       33.0                        \n",
       "\n",
       "                 What is the volume of estimated probable hydrocarbons reserves?  \\\n",
       "accuracy                                                       1.0                 \n",
       "f1_score                                                       1.0                 \n",
       "recall_score                                                   1.0                 \n",
       "precision_score                                                1.0                 \n",
       "support                                                        1.0                 \n",
       "\n",
       "                 What is the volume of estimated proven hydrocarbons reserves?  \n",
       "accuracy                                                       1.0              \n",
       "f1_score                                                       1.0              \n",
       "recall_score                                                   1.0              \n",
       "precision_score                                                1.0              \n",
       "support                                                       47.0              \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evalute performance\n",
    "groups = test_data.groupby(\"question\")\n",
    "scores = {}\n",
    "for group, data in groups:\n",
    "    pred = data.pred\n",
    "    true = data.label\n",
    "    scores[group] = {}\n",
    "    scores[group][\"accuracy\"] = accuracy_score(true, pred)\n",
    "    scores[group][\"f1_score\"] = f1_score(true, pred)\n",
    "    scores[group][\"recall_score\"] = recall_score(true, pred)\n",
    "    scores[group][\"precision_score\"] = precision_score(true, pred)\n",
    "    scores[group][\"support\"] = len(pred)\n",
    "\n",
    "# kpi wise performance metrics\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e04eb44-12e6-4136-a90e-79d92a03c18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9179571080911388"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.loc['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64fb745-7077-4382-8401-33ec8b730a62",
   "metadata": {},
   "source": [
    "This f1 score of ~91.7% is better. So far this notebook has successfully used huggingface transformer for the relevance task. The farm model had an f1 score of around 91% so this surpases the original f1-score.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0d719-245c-4902-bec5-f2de2762302b",
   "metadata": {},
   "source": [
    "## Save model locally and to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af468cea-7482-4a42-b2e9-b840184967ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/app-root/src/aicoe-osc-demo/models/transformers/RELEVANCE.zip'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_path = '/opt/app-root/src/aicoe-osc-demo/models/transformers/RELEVANCE'\n",
    "trainer.save_model(local_model_path)\n",
    "shutil.make_archive(local_model_path, 'zip', local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cf537fa-e355-4593-920b-3c24d56c9dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = BytesIO()\n",
    "with zipfile.ZipFile(buffer, 'a') as z:\n",
    "    for dirname, _, files in os.walk(local_model_path):\n",
    "        for f in files:\n",
    "            f_path = os.path.join(dirname, f)\n",
    "            with open (f_path, 'rb') as file_content:\n",
    "                z.writestr(f\"RELEVANCE/{f}\", file_content.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bc2c5d7-c37b-42ce-9ca2-1a4b13b828d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'CAH611SY1SHVETHG',\n",
       "  'HostId': 'GuFNxgxi116yMs8jPJo7aUpKXq8zwT7ELbrNnIJC6gB+gDlnUyeE/Zv6nYMqgAoH0IQD17nJqC0=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'GuFNxgxi116yMs8jPJo7aUpKXq8zwT7ELbrNnIJC6gB+gDlnUyeE/Zv6nYMqgAoH0IQD17nJqC0=',\n",
       "   'x-amz-request-id': 'CAH611SY1SHVETHG',\n",
       "   'date': 'Thu, 20 Oct 2022 17:43:17 GMT',\n",
       "   'etag': '\"2f37148816b514eeeee532469d37e4ef\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"2f37148816b514eeeee532469d37e4ef\"'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.seek(0)\n",
    "# upload model to s3\n",
    "s3c._upload_bytes(\n",
    "    buffer_bytes=buffer,\n",
    "    prefix=config.BASE_SAVED_MODELS_S3_PREFIX,\n",
    "    key=\"RELEVANCE.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad04dc1d-0fc2-4952-aabb-3fb0e5d9d9ef",
   "metadata": {},
   "source": [
    "## Sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9659775b-ce80-4c31-b3ff-309ae5642f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = str(config.BASE_PROCESSED_DATA)+'/rel_test_split.csv'\n",
    "test_data = pd.read_csv(test_data_path, index_col=0)\n",
    "test_data.rename(columns={'text':'question', 'text_b':'sentence'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "146beabf-9401-4974-9e00-7a1709b8abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stub='zoo:nlp/text_classification/distilbert-none/pytorch/huggingface/mnli/pruned80_quant-none-vnni'\n",
    "path='/opt/app-root/src/aicoe-osc-demo/models/distilbert'\n",
    "sparse_model = Model(stub, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c1bbb-40ed-469e-82ec-3e2066b884f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparse_model = Model(stub, path)\n",
    "sparse_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "912f2b4c-899e-4c3f-a621-b2d99966e617",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /opt/app-root/src/aicoe-osc-demo/models/distilbert/training/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"/opt/app-root/src/aicoe-osc-demo/models/distilbert/training\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /opt/app-root/src/aicoe-osc-demo/models/distilbert/training/pytorch_model.bin\n",
      "Some weights of the model checkpoint at /opt/app-root/src/aicoe-osc-demo/models/distilbert/training were not used when initializing DistilBertForSequenceClassification: ['distilbert.transformer.layer.0.attention.v_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.k_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.3.ffn.lin1.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.attention.q_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.out_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.3.attention.v_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.4.attention.k_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.0.ffn.lin2.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.1.ffn.lin1.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.v_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'pre_classifier.module.bias', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.2.ffn.lin2.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.k_lin.module.bias', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.k_lin.module.weight', 'distilbert.transformer.layer.3.attention.v_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.1.attention.v_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.k_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.4.attention.q_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.v_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.0.ffn.lin1.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.4.ffn.lin1.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.attention.out_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.ffn.lin2.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.4.ffn.lin1.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.out_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.embeddings.word_embeddings.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.v_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.k_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.0.ffn.lin2.module.bias', 'distilbert.transformer.layer.3.attention.out_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.out_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.k_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.2.ffn.lin1.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.out_lin.module.bias', 'distilbert.transformer.layer.3.ffn.lin1.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.0.attention.out_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.5.ffn.lin1.quant.activation_post_process.scale', 'distilbert.transformer.layer.5.attention.v_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.ffn.lin1.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.0.ffn.lin1.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.attention.v_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.q_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.v_lin.module.weight', 'distilbert.transformer.layer.2.ffn.lin2.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.out_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.k_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.q_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.out_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.q_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.1.attention.v_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.3.attention.out_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.out_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.out_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.k_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.k_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.3.ffn.lin2.module.weight', 'distilbert.embeddings.position_embeddings.weight_fake_quant.scale', 'distilbert.transformer.layer.1.attention.v_lin.module.bias', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.q_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.1.ffn.lin1.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.v_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.ffn.lin2.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.ffn.lin2.module.weight', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.0.ffn.lin1.quant.activation_post_process.scale', 'distilbert.transformer.layer.3.attention.q_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.0.attention.out_lin.module.weight', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.ffn.lin1.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.ffn.lin1.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.1.ffn.lin2.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.0.ffn.lin1.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.v_lin.module.weight', 'distilbert.transformer.layer.0.attention.out_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.out_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.0.attention.k_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.2.ffn.lin2.module.weight_fake_quant.scale', 'distilbert.transformer.layer.5.attention.k_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.ffn.lin2.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.q_lin.quant.activation_post_process.activation_post_process.min_val', 'classifier.module.bias', 'distilbert.transformer.layer.3.attention.v_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.q_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.k_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.5.attention.q_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.ffn.lin1.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.q_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.q_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.4.attention.k_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.v_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.2.ffn.lin1.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.3.attention.k_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.k_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.2.ffn.lin2.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.v_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.4.attention.out_lin.module.bias', 'distilbert.transformer.layer.2.ffn.lin2.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.v_lin.module.weight_fake_quant.fake_quant_enabled', 'classifier.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.out_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.1.attention.v_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.2.attention.v_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.v_lin.module.bias', 'distilbert.transformer.layer.3.attention.out_lin.module.weight', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.ffn.lin1.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.q_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.2.attention.out_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.3.attention.v_lin.module.bias', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.q_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.out_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.ffn.lin1.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.out_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'classifier.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.q_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.embeddings.word_embeddings.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.ffn.lin2.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'pre_classifier.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.embeddings.word_embeddings.weight_fake_quant.zero_point', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.3.ffn.lin1.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.k_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.3.attention.q_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.2.attention.q_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.0.attention.k_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.v_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.3.attention.out_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.2.ffn.lin1.module.bias', 'distilbert.transformer.layer.3.attention.k_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.out_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.out_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.5.ffn.lin1.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.ffn.lin1.module.weight', 'distilbert.transformer.layer.3.ffn.lin1.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.5.attention.q_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.q_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.v_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.2.attention.q_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.v_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.out_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.out_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.attention.k_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.0.ffn.lin2.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.4.attention.q_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.5.ffn.lin2.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.0.attention.q_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.attention.v_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.5.ffn.lin2.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.v_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.3.attention.k_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.v_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.5.ffn.lin1.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.attention.k_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.ffn.lin2.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.3.attention.k_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.4.attention.out_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.2.attention.out_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.3.attention.v_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.ffn.lin1.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.k_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.2.ffn.lin1.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.ffn.lin2.module.weight', 'distilbert.transformer.layer.4.attention.k_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.v_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.ffn.lin1.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.ffn.lin2.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.4.ffn.lin1.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.v_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.ffn.lin2.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.out_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.5.attention.q_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.4.ffn.lin1.module.bias', 'distilbert.transformer.layer.2.ffn.lin2.quant.activation_post_process.scale', 'distilbert.transformer.layer.3.attention.q_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.ffn.lin2.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.5.attention.out_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.k_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.3.attention.q_lin.module.weight', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.q_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.v_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.k_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.q_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.3.attention.out_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.2.attention.out_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.1.attention.q_lin.module.bias', 'distilbert.transformer.layer.1.attention.q_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.k_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.3.ffn.lin1.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.k_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'classifier.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.k_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.v_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.0.ffn.lin1.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.0.ffn.lin1.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.0.ffn.lin1.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.1.ffn.lin1.module.bias', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.3.attention.out_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.transformer.layer.4.attention.v_lin.quant.activation_post_process.scale', 'pre_classifier.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.1.ffn.lin2.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.2.ffn.lin1.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.out_lin.module.weight_fake_quant.activation_post_process.min_val', 'classifier.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.5.ffn.lin1.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.ffn.lin2.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.0.ffn.lin2.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.3.attention.q_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.3.attention.k_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.3.attention.k_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.5.ffn.lin1.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.0.ffn.lin2.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.ffn.lin2.quant.activation_post_process.observer_enabled', 'pre_classifier.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.4.ffn.lin2.quant.activation_post_process.zero_point', 'pre_classifier.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.ffn.lin2.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.v_lin.quant.activation_post_process.scale', 'distilbert.embeddings.word_embeddings.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.out_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.ffn.lin1.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.k_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.1.attention.q_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.2.attention.k_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.ffn.lin2.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.4.attention.v_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.5.ffn.lin1.module.weight_fake_quant.scale', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.3.attention.k_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.ffn.lin2.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.0.attention.out_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.out_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.out_lin.quant.activation_post_process.zero_point', 'distilbert.embeddings.position_embeddings.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.5.ffn.lin2.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.5.attention.out_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.q_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.k_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.out_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.q_lin.module.bias', 'distilbert.transformer.layer.2.attention.out_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.attention.k_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.embeddings.position_embeddings.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.q_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.q_lin.module.bias', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.q_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.q_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.v_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.transformer.layer.1.attention.q_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.q_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.ffn.lin2.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.q_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.4.ffn.lin2.module.weight_fake_quant.activation_post_process.min_val', 'pre_classifier.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.q_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.out_lin.module.weight', 'distilbert.transformer.layer.5.attention.k_lin.module.weight', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.attention.v_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.ffn.lin1.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.3.ffn.lin2.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.5.attention.q_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.ffn.lin2.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.2.ffn.lin2.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.k_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.q_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.0.attention.k_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.q_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.ffn.lin1.module.bias', 'distilbert.transformer.layer.2.ffn.lin2.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.5.ffn.lin1.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'classifier.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.k_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.0.ffn.lin2.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.4.ffn.lin1.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.ffn.lin2.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.v_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.4.ffn.lin2.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.k_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.ffn.lin2.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.2.ffn.lin2.module.bias', 'pre_classifier.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.5.ffn.lin2.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.5.attention.v_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.2.ffn.lin1.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.k_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.q_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.4.ffn.lin2.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.out_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.v_lin.module.bias', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.ffn.lin2.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.k_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.4.ffn.lin1.quant.activation_post_process.scale', 'distilbert.transformer.layer.2.attention.v_lin.module.bias', 'distilbert.transformer.layer.2.ffn.lin1.module.weight', 'distilbert.transformer.layer.1.ffn.lin1.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.4.attention.out_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.2.attention.q_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.out_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.2.ffn.lin1.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.v_lin.module.weight', 'distilbert.transformer.layer.5.attention.out_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.q_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.5.attention.k_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.k_lin.module.bias', 'distilbert.transformer.layer.0.attention.v_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.transformer.layer.3.attention.v_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.k_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.q_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.ffn.lin2.quant.activation_post_process.scale', 'distilbert.transformer.layer.4.attention.q_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.1.attention.out_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.attention.k_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.ffn.lin2.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.4.ffn.lin2.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.k_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.ffn.lin2.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.q_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.v_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.5.attention.out_lin.module.bias', 'distilbert.transformer.layer.3.attention.q_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.5.ffn.lin1.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.ffn.lin2.quant.activation_post_process.scale', 'distilbert.transformer.layer.3.ffn.lin2.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.q_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.attention.k_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.k_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.5.ffn.lin1.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.0.ffn.lin1.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.k_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.v_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.4.attention.out_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.transformer.layer.5.ffn.lin1.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.0.attention.k_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.3.ffn.lin2.quant.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.k_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.v_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.k_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.5.attention.q_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.k_lin.module.weight', 'distilbert.transformer.layer.4.ffn.lin1.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.5.attention.v_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.3.attention.k_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.k_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.v_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.q_lin.module.weight', 'distilbert.transformer.layer.4.attention.k_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.2.attention.v_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.ffn.lin1.quant.activation_post_process.scale', 'distilbert.transformer.layer.3.attention.v_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.5.ffn.lin2.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.2.ffn.lin2.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.3.ffn.lin2.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.0.attention.out_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.1.attention.k_lin.module.bias', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.ffn.lin2.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.attention.k_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.2.attention.out_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.2.ffn.lin1.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.5.attention.out_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.out_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.1.attention.k_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.0.attention.q_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.out_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.3.ffn.lin2.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.2.attention.q_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.5.attention.k_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.q_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.1.ffn.lin2.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.v_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.out_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.k_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.q_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.attention.k_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.q_lin.module.bias', 'distilbert.transformer.layer.4.attention.k_lin.module.weight', 'distilbert.transformer.layer.3.attention.out_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.ffn.lin2.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.k_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.5.attention.q_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.3.attention.q_lin.module.bias', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.out_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.v_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.3.ffn.lin1.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.ffn.lin1.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.out_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.0.attention.k_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.attention.v_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.out_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.3.attention.q_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.ffn.lin1.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.2.ffn.lin1.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.out_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.k_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.attention.out_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.0.attention.k_lin.module.weight', 'distilbert.transformer.layer.1.ffn.lin2.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.v_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.out_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.q_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.5.attention.k_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.5.ffn.lin2.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.3.ffn.lin2.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.v_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.3.ffn.lin1.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.v_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.q_lin.module.weight_fake_quant.activation_post_process.max_val', 'pre_classifier.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.v_lin.quant.activation_post_process.observer_enabled', 'classifier.module.weight', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.v_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.5.attention.q_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.0.attention.out_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.2.attention.v_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.4.attention.q_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.0.attention.q_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.4.attention.out_lin.quant.activation_post_process.observer_enabled', 'classifier.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.4.attention.k_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.v_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.attention.out_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.2.ffn.lin1.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.5.attention.q_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.0.attention.q_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.v_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.k_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.ffn.lin2.module.weight_fake_quant.scale', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.ffn.lin2.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.4.ffn.lin2.module.bias', 'distilbert.transformer.layer.2.ffn.lin2.module.weight', 'distilbert.transformer.layer.1.ffn.lin2.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.0.attention.v_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.3.ffn.lin1.module.weight_fake_quant.scale', 'distilbert.transformer.layer.2.attention.k_lin.module.bias', 'distilbert.transformer.layer.5.ffn.lin1.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.q_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.ffn.lin2.module.bias', 'distilbert.transformer.layer.1.attention.q_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.4.ffn.lin1.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.ffn.lin2.module.weight', 'distilbert.transformer.layer.1.attention.out_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.out_lin.module.bias', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'pre_classifier.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.1.attention.out_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.ffn.lin2.module.weight_fake_quant.scale', 'distilbert.transformer.layer.1.ffn.lin1.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.embeddings.position_embeddings.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.0.ffn.lin1.module.bias', 'distilbert.transformer.layer.0.attention.v_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.0.ffn.lin1.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.4.attention.k_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.0.attention.v_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.2.ffn.lin1.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.2.ffn.lin1.module.weight_fake_quant.scale', 'distilbert.transformer.layer.0.attention.out_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.attention.out_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.0.ffn.lin1.module.weight', 'distilbert.transformer.layer.3.attention.k_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.ffn.lin2.quant.activation_post_process.scale', 'distilbert.transformer.layer.1.ffn.lin2.quant.activation_post_process.activation_post_process.max_val', 'classifier.quant.activation_post_process.scale', 'distilbert.transformer.layer.2.attention.v_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.ffn.lin1.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.out_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.v_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.0.ffn.lin1.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.v_lin.module.weight_fake_quant.observer_enabled', 'distilbert.embeddings.position_embeddings.weight_fake_quant.zero_point', 'distilbert.transformer.layer.5.attention.v_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'classifier.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.out_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.k_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.1.ffn.lin1.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.3.ffn.lin1.module.weight_fake_quant.activation_post_process.min_val', 'classifier.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.0.attention.q_lin.module.weight', 'distilbert.transformer.layer.4.ffn.lin1.module.weight', 'distilbert.transformer.layer.3.attention.q_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.2.attention.k_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.1.ffn.lin1.module.weight_fake_quant.scale', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.3.attention.out_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.k_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.2.attention.k_lin.module.weight', 'distilbert.transformer.layer.3.attention.q_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.ffn.lin2.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.ffn.lin2.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.2.attention.k_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.v_lin.quant.activation_post_process.activation_post_process.min_val', 'pre_classifier.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.ffn.lin2.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.2.ffn.lin1.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.2.ffn.lin2.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.2.attention.k_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.q_lin.module.weight', 'distilbert.transformer.layer.0.ffn.lin1.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.0.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.3.attention.out_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.v_lin.quant.activation_post_process.activation_post_process.max_val', 'classifier.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.attention.v_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.5.ffn.lin2.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.0.ffn.lin2.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.q_lin.module.weight', 'pre_classifier.module.weight', 'distilbert.transformer.layer.5.attention.k_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.v_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.2.ffn.lin1.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.out_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.q_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.scale', 'distilbert.transformer.layer.3.attention.v_lin.module.weight', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.1.ffn.lin1.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.ffn.lin2.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.transformer.layer.3.attention.q_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.ffn.lin2.module.bias', 'distilbert.transformer.layer.5.attention.out_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.v_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.out_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.out_lin.module.bias', 'distilbert.transformer.layer.3.attention.k_lin.module.bias', 'distilbert.transformer.layer.5.attention.out_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.2.attention.q_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.embeddings.word_embeddings.weight_fake_quant.observer_enabled', 'classifier.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.2.attention.out_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.2.attention.v_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.v_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.attention.k_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.5.attention.q_lin.module.weight', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.v_lin.module.weight', 'distilbert.transformer.layer.5.attention.q_lin.module.bias', 'distilbert.transformer.layer.5.attention.k_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.5.ffn.lin1.module.weight', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.3.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'classifier.module.weight_fake_quant.scale', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.transformer.layer.0.attention.q_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.5.attention.q_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.5.ffn.lin2.module.bias', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.ffn.lin1.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.2.attention.k_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.attention.q_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.ffn.lin1.module.weight_fake_quant.scale', 'distilbert.transformer.layer.1.attention.out_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.attention.out_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.5.attention.out_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.4.attention.out_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.3.ffn.lin1.quant.activation_post_process.scale', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.observer_enabled', 'pre_classifier.module.weight_fake_quant.scale', 'distilbert.transformer.layer.5.attention.q_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.3.attention.k_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.3.attention.v_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.attention.k_lin.quant.activation_post_process.scale', 'pre_classifier.quant.activation_post_process.scale', 'distilbert.transformer.layer.4.attention.q_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.4.attention.q_lin.quant.activation_post_process.scale', 'pre_classifier.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.1.attention.v_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.4.ffn.lin1.module.weight_fake_quant.scale', 'distilbert.transformer.layer.1.ffn.lin1.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.2.ffn.lin2.quant.activation_post_process.activation_post_process.max_val', 'classifier.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.0.attention.out_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.attention.k_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.1.attention.q_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.ffn.lin2.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.0.attention.v_lin.module.weight', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.2.attention.out_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.k_lin.module.bias', 'distilbert.transformer.layer.0.attention.q_lin.quant.activation_post_process.scale', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.embeddings.position_embeddings.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.attention.k_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.1.ffn.lin2.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.out_lin.module.weight', 'distilbert.transformer.layer.0.attention.out_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.0.attention.k_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.1.attention.out_lin.module.bias', 'distilbert.transformer.layer.2.attention.v_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.3.ffn.lin2.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.v_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.q_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.input_quant_stubs.1.activation_post_process.fake_quant_enabled', 'pre_classifier.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.0.attention.out_lin.module.weight_fake_quant.zero_point', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.attention.context_layer_matmul.input_quant_stubs.1.activation_post_process.zero_point', 'distilbert.embeddings.position_embeddings.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.0.attention.v_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.1.ffn.lin1.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.5.ffn.lin2.module.weight_fake_quant.scale', 'distilbert.transformer.layer.3.attention.v_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.embeddings.word_embeddings.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.4.ffn.lin2.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.0.attention.q_lin.quant.activation_post_process.zero_point', 'classifier.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.q_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.observer_enabled', 'distilbert.transformer.layer.0.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.observer_enabled', 'pre_classifier.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.5.attention.k_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.3.ffn.lin1.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.ffn.lin1.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.3.ffn.lin2.module.weight_fake_quant.scale', 'distilbert.transformer.layer.2.attention.v_lin.quant.activation_post_process.observer_enabled', 'distilbert.transformer.layer.4.ffn.lin2.module.weight', 'distilbert.embeddings.word_embeddings.weight_fake_quant.scale', 'distilbert.transformer.layer.0.attention.k_lin.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.4.attention.q_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.ffn.lin2.module.weight_fake_quant.scale', 'distilbert.transformer.layer.2.attention.v_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.5.attention.out_lin.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.1.attention.out_lin.module.weight', 'distilbert.transformer.layer.4.attention.v_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.ffn.lin1.module.weight', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.scale', 'distilbert.transformer.layer.1.ffn.lin2.quant.activation_post_process.scale', 'distilbert.transformer.layer.5.attention.v_lin.module.weight_fake_quant.scale', 'distilbert.transformer.layer.0.ffn.lin2.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.1.attention.k_lin.module.weight_fake_quant.activation_post_process.min_val', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.attention.context_layer_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.3.attention.out_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.4.attention.v_lin.module.weight_fake_quant.activation_post_process.max_val', 'distilbert.transformer.layer.1.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.zero_point', 'distilbert.transformer.layer.4.attention.q_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.5.attention.v_lin.module.bias', 'distilbert.transformer.layer.0.attention.v_lin.quant.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.4.attention.out_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.2.attention.q_lin.module.weight_fake_quant.observer_enabled', 'distilbert.transformer.layer.2.attention.v_lin.quant.activation_post_process.zero_point', 'distilbert.transformer.layer.5.ffn.lin2.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.1.ffn.lin1.quant.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.5.ffn.lin1.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.3.ffn.lin1.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.4.attention.out_lin.module.weight_fake_quant.activation_post_process.eps', 'distilbert.transformer.layer.2.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.5.attention.v_lin.module.weight_fake_quant.fake_quant_enabled', 'distilbert.transformer.layer.3.ffn.lin1.module.bias', 'distilbert.transformer.layer.5.attention.out_lin.module.weight', 'distilbert.transformer.layer.4.attention.q_lin.quant.activation_post_process.activation_post_process.max_val', 'distilbert.transformer.layer.5.attention.attention_scores_matmul.input_quant_stubs.0.activation_post_process.activation_post_process.eps', 'distilbert.transformer.layer.1.ffn.lin1.quant.activation_post_process.scale', 'distilbert.transformer.layer.4.attention.attention_scores_matmul.output_quant_stubs.0.activation_post_process.fake_quant_enabled', 'distilbert.transformer.layer.3.ffn.lin2.quant.activation_post_process.activation_post_process.min_val', 'distilbert.transformer.layer.0.attention.v_lin.quant.activation_post_process.activation_post_process.max_val']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /opt/app-root/src/aicoe-osc-demo/models/distilbert/training and are newly initialized: ['classifier.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'pre_classifier.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'pre_classifier.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'classifier.bias', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 2\n",
    "path='/opt/app-root/src/aicoe-osc-demo/models/distilbert/training'\n",
    "sparse_model = AutoModelForSequenceClassification.from_pretrained(path, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "57fdd92a-fc1e-437d-94fb-6583ecb1608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: question, sentence, __index_level_0__. If question, sentence, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2033\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2048\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2048' max='2048' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2048/2048 03:58, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.191400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.072800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2048, training_loss=0.1870914592873305, metrics={'train_runtime': 240.8874, 'train_samples_per_second': 135.034, 'train_steps_per_second': 8.502, 'total_flos': 1815869827636536.0, 'train_loss': 0.1870914592873305, 'epoch': 16.0})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    sparse_model,\n",
    "    args,\n",
    "    train_dataset=encoded_climate_dataset[\"train\"],\n",
    "    eval_dataset=None,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "48e9ad4a-cb92-41a0-ba3d-e884433cbcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: question, sentence, __index_level_0__. If question, sentence, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 509\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_runtime': 1.1964,\n",
       " 'eval_samples_per_second': 425.446,\n",
       " 'eval_steps_per_second': 26.747,\n",
       " 'epoch': 16.0}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=encoded_climate_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "59df5d14-4057-473e-bdb8-4e76ad925712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: question, sentence, __index_level_0__. If question, sentence, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 509\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(encoded_climate_dataset['test'])\n",
    "test_data[\"pred\"] = np.argmax(pred.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "91bd65dc-5058-43c2-a1ca-16b83f375b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>In which year was the annual report or the sustainability report published?</th>\n",
       "      <th>What is the annual total production from coal?</th>\n",
       "      <th>What is the base year for carbon reduction commitment?</th>\n",
       "      <th>What is the climate commitment scenario considered?</th>\n",
       "      <th>What is the company name?</th>\n",
       "      <th>What is the target carbon reduction in percentage?</th>\n",
       "      <th>What is the target year for climate commitment?</th>\n",
       "      <th>What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?</th>\n",
       "      <th>What is the total amount of energy indirect greenhouse gases emissions referred to as scope 2 emissions?</th>\n",
       "      <th>What is the total amount of scope 1 and 2 greenhouse gases emissions?</th>\n",
       "      <th>...</th>\n",
       "      <th>What is the total amount of upstream energy indirect greenhouse gases emissions referred to as scope 3 emissions?</th>\n",
       "      <th>What is the total installed capacity from coal?</th>\n",
       "      <th>What is the total installed capacity from lignite (brown coal)?</th>\n",
       "      <th>What is the total volume of crude oil liquid production?</th>\n",
       "      <th>What is the total volume of hydrocarbons production?</th>\n",
       "      <th>What is the total volume of natural gas liquid production?</th>\n",
       "      <th>What is the total volume of natural gas production?</th>\n",
       "      <th>What is the total volume of proven and probable hydrocarbons reserves?</th>\n",
       "      <th>What is the volume of estimated probable hydrocarbons reserves?</th>\n",
       "      <th>What is the volume of estimated proven hydrocarbons reserves?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.858696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.850575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>0.948718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score</th>\n",
       "      <td>0.770833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 In which year was the annual report or the sustainability report published?  \\\n",
       "accuracy                                                  0.858696                             \n",
       "f1_score                                                  0.850575                             \n",
       "recall_score                                              0.948718                             \n",
       "precision_score                                           0.770833                             \n",
       "support                                                  92.000000                             \n",
       "\n",
       "                 What is the annual total production from coal?  \\\n",
       "accuracy                                                    1.0   \n",
       "f1_score                                                    1.0   \n",
       "recall_score                                                1.0   \n",
       "precision_score                                             1.0   \n",
       "support                                                     6.0   \n",
       "\n",
       "                 What is the base year for carbon reduction commitment?  \\\n",
       "accuracy                                                       1.0        \n",
       "f1_score                                                       1.0        \n",
       "recall_score                                                   1.0        \n",
       "precision_score                                                1.0        \n",
       "support                                                       25.0        \n",
       "\n",
       "                 What is the climate commitment scenario considered?  \\\n",
       "accuracy                                                  0.920000     \n",
       "f1_score                                                  0.909091     \n",
       "recall_score                                              0.909091     \n",
       "precision_score                                           0.909091     \n",
       "support                                                  25.000000     \n",
       "\n",
       "                 What is the company name?  \\\n",
       "accuracy                          0.830189   \n",
       "f1_score                          0.790698   \n",
       "recall_score                      0.850000   \n",
       "precision_score                   0.739130   \n",
       "support                          53.000000   \n",
       "\n",
       "                 What is the target carbon reduction in percentage?  \\\n",
       "accuracy                                                       1.0    \n",
       "f1_score                                                       1.0    \n",
       "recall_score                                                   1.0    \n",
       "precision_score                                                1.0    \n",
       "support                                                       34.0    \n",
       "\n",
       "                 What is the target year for climate commitment?  \\\n",
       "accuracy                                                0.956522   \n",
       "f1_score                                                0.952381   \n",
       "recall_score                                            1.000000   \n",
       "precision_score                                         0.909091   \n",
       "support                                                46.000000   \n",
       "\n",
       "                 What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?  \\\n",
       "accuracy                                                  0.833333                                                 \n",
       "f1_score                                                  0.857143                                                 \n",
       "recall_score                                              1.000000                                                 \n",
       "precision_score                                           0.750000                                                 \n",
       "support                                                  18.000000                                                 \n",
       "\n",
       "                 What is the total amount of energy indirect greenhouse gases emissions referred to as scope 2 emissions?  \\\n",
       "accuracy                                                  0.923077                                                          \n",
       "f1_score                                                  0.857143                                                          \n",
       "recall_score                                              1.000000                                                          \n",
       "precision_score                                           0.750000                                                          \n",
       "support                                                  13.000000                                                          \n",
       "\n",
       "                 What is the total amount of scope 1 and 2 greenhouse gases emissions?  \\\n",
       "accuracy                                                       1.0                       \n",
       "f1_score                                                       1.0                       \n",
       "recall_score                                                   1.0                       \n",
       "precision_score                                                1.0                       \n",
       "support                                                        2.0                       \n",
       "\n",
       "                 ...  \\\n",
       "accuracy         ...   \n",
       "f1_score         ...   \n",
       "recall_score     ...   \n",
       "precision_score  ...   \n",
       "support          ...   \n",
       "\n",
       "                 What is the total amount of upstream energy indirect greenhouse gases emissions referred to as scope 3 emissions?  \\\n",
       "accuracy                                                       1.0                                                                   \n",
       "f1_score                                                       1.0                                                                   \n",
       "recall_score                                                   1.0                                                                   \n",
       "precision_score                                                1.0                                                                   \n",
       "support                                                       15.0                                                                   \n",
       "\n",
       "                 What is the total installed capacity from coal?  \\\n",
       "accuracy                                                     1.0   \n",
       "f1_score                                                     1.0   \n",
       "recall_score                                                 1.0   \n",
       "precision_score                                              1.0   \n",
       "support                                                      4.0   \n",
       "\n",
       "                 What is the total installed capacity from lignite (brown coal)?  \\\n",
       "accuracy                                                       1.0                 \n",
       "f1_score                                                       0.0                 \n",
       "recall_score                                                   0.0                 \n",
       "precision_score                                                0.0                 \n",
       "support                                                        1.0                 \n",
       "\n",
       "                 What is the total volume of crude oil liquid production?  \\\n",
       "accuracy                                                       1.0          \n",
       "f1_score                                                       1.0          \n",
       "recall_score                                                   1.0          \n",
       "precision_score                                                1.0          \n",
       "support                                                        3.0          \n",
       "\n",
       "                 What is the total volume of hydrocarbons production?  \\\n",
       "accuracy                                                  0.971429      \n",
       "f1_score                                                  0.965517      \n",
       "recall_score                                              1.000000      \n",
       "precision_score                                           0.933333      \n",
       "support                                                  70.000000      \n",
       "\n",
       "                 What is the total volume of natural gas liquid production?  \\\n",
       "accuracy                                                       1.0            \n",
       "f1_score                                                       1.0            \n",
       "recall_score                                                   1.0            \n",
       "precision_score                                                1.0            \n",
       "support                                                        4.0            \n",
       "\n",
       "                 What is the total volume of natural gas production?  \\\n",
       "accuracy                                                       1.0     \n",
       "f1_score                                                       1.0     \n",
       "recall_score                                                   1.0     \n",
       "precision_score                                                1.0     \n",
       "support                                                       16.0     \n",
       "\n",
       "                 What is the total volume of proven and probable hydrocarbons reserves?  \\\n",
       "accuracy                                                  0.939394                        \n",
       "f1_score                                                  0.941176                        \n",
       "recall_score                                              0.941176                        \n",
       "precision_score                                           0.941176                        \n",
       "support                                                  33.000000                        \n",
       "\n",
       "                 What is the volume of estimated probable hydrocarbons reserves?  \\\n",
       "accuracy                                                       1.0                 \n",
       "f1_score                                                       1.0                 \n",
       "recall_score                                                   1.0                 \n",
       "precision_score                                                1.0                 \n",
       "support                                                        1.0                 \n",
       "\n",
       "                 What is the volume of estimated proven hydrocarbons reserves?  \n",
       "accuracy                                                       1.0              \n",
       "f1_score                                                       1.0              \n",
       "recall_score                                                   1.0              \n",
       "precision_score                                                1.0              \n",
       "support                                                       47.0              \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evalute performance\n",
    "groups = test_data.groupby(\"question\")\n",
    "scores = {}\n",
    "for group, data in groups:\n",
    "    pred = data.pred\n",
    "    true = data.label\n",
    "    scores[group] = {}\n",
    "    scores[group][\"accuracy\"] = accuracy_score(true, pred)\n",
    "    scores[group][\"f1_score\"] = f1_score(true, pred)\n",
    "    scores[group][\"recall_score\"] = recall_score(true, pred)\n",
    "    scores[group][\"precision_score\"] = precision_score(true, pred)\n",
    "    scores[group][\"support\"] = len(pred)\n",
    "\n",
    "# kpi wise performance metrics\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b5b2250b-ff83-4f41-a91d-fd8cb16902a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9106535083232097"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.loc['f1_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a063532f-d87e-487d-861d-704cd7895a67",
   "metadata": {},
   "source": [
    "This is similar as previous model but slightly less. Next let's see what the inference timings are for these models in the transformer_inference notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
