{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Relevance Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset has been [extracted](pdf_text_extraction.ipynb) and [curated](pdf_text_curation.ipynb), we will train the relevance classifier model in this notebook. The model trained is comprised of a transformer model (e.g., BERT) that can be loaded pre-trained on the NQ dataset into the pipeline and then be fine-tuned on the curated data for our specific relevance detection task.\n",
    "\n",
    "Our pipeline includes components that are provided by the FARM library. FARM is a framework which facilitates transfer learning tasks for BERT based models. Documentation for FARM is available here: https://farm.deepset.ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/13/2022 16:02:14 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import config\n",
    "import zipfile\n",
    "import pathlib\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "from src.models import FARMTrainer\n",
    "from src.data.s3_communication import S3Communication, S3FileType\n",
    "\n",
    "from config_farm_train import (\n",
    "    FileConfig,\n",
    "    ModelConfig,\n",
    "    MLFlowConfig,\n",
    "    TrainingConfig,\n",
    "    TokenizerConfig,\n",
    "    ProcessorConfig,\n",
    ")\n",
    "from farm.infer import Inferencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting training, parameters for each component of the training pipeline must be set. For this we create `config` objects which hold these parameters. Default values have already been set but they can be easily changed. To do so, you can manually update the parameters in the corresponding config file:\n",
    "\n",
    "`aicoe-osc-demo/notebooks/demo2/config_farm_train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings data files and checkpoints parameters\n",
    "file_config = FileConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for the processor component\n",
    "processor_config = ProcessorConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for the tokenizer\n",
    "tokenizer_config = TokenizerConfig(config.EXPERIMENT_NAME)\n",
    "# NOTE: specifically for tokenizer, we need to ensure root dir is a string\n",
    "tokenizer_config.root = str(tokenizer_config.root)\n",
    "\n",
    "# Settings for the model\n",
    "model_config = ModelConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for training\n",
    "train_config = TrainingConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for training\n",
    "mlflow_config = MLFlowConfig(config.EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the value for some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment_name: \n",
      " test-demo-2 \n",
      "\n",
      "Data directory: \n",
      " /opt/app-root/src/aicoe-osc-demo/data \n",
      "\n",
      "Curated dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo/data/curation/esg_TEXT_dataset.csv \n",
      "\n",
      "Split train/validation ratio: \n",
      "0.2 \n",
      "\n",
      "Training dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo/data/kpi_train_split.csv \n",
      "\n",
      "Validation dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo/data/kpi_val_split.csv \n",
      "\n",
      "Directory where trained model is saved: \n",
      " /opt/app-root/src/aicoe-osc-demo/models/RELEVANCE \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Experiment_name: \\n {file_config.experiment_name} \\n\")\n",
    "print(f\"Data directory: \\n {file_config.data_dir} \\n\")\n",
    "print(f\"Curated dataset path: \\n {file_config.curated_data} \\n\")\n",
    "print(f\"Split train/validation ratio: \\n{file_config.dev_split} \\n\")\n",
    "print(f\"Training dataset path: \\n {file_config.train_filename} \\n\")\n",
    "print(f\"Validation dataset path: \\n {file_config.dev_filename} \\n\")\n",
    "print(f\"Directory where trained model is saved: \\n {file_config.saved_models_dir} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens per example: 128 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max number of tokens per example: {processor_config.max_seq_len} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Use GPU: {train_config.use_cuda} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning_rate: 1e-05 \n",
      "\n",
      "Number of epochs for fine tuning: 1 \n",
      "\n",
      "Batch size: 1 \n",
      "\n",
      "Perform Cross validation: False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Learning_rate: {train_config.learning_rate} \\n\")\n",
    "print(f\"Number of epochs for fine tuning: {train_config.n_epochs} \\n\")\n",
    "print(f\"Batch size: {train_config.batch_size} \\n\")\n",
    "print(f\"Perform Cross validation: {train_config.run_cv} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Pretrained Model\n",
    "\n",
    "We already have a trained relevance classifier on Google's large NQ dataset. We download it and then save it in the following directory: `file_config.saved_models_dir / \"relevance_roberta\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running in Automation using Elyra and Kubeflow Pipelines,\n",
    "# set AUTOMATION = 1 as an environment variable\n",
    "if os.getenv(\"AUTOMATION\"):\n",
    "    # extracted pdfs\n",
    "    if not os.path.exists(config.BASE_EXTRACTION_FOLDER):\n",
    "        config.BASE_EXTRACTION_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # curated pdfs\n",
    "    if not os.path.exists(config.BASE_CURATION_FOLDER):\n",
    "        config.BASE_CURATION_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # processed data\n",
    "    if not os.path.exists(config.BASE_PROCESSED_DATA):\n",
    "        config.BASE_PROCESSED_DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # load dir\n",
    "    if not os.path.exists(model_config.load_dir):\n",
    "        pathlib.Path(model_config.load_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # download extracted pdfs from s3\n",
    "    s3c.download_files_in_prefix_to_dir(\n",
    "        config.BASE_EXTRACTION_S3_PREFIX,\n",
    "        config.BASE_EXTRACTION_FOLDER,\n",
    "    )\n",
    "    # download curated pdfs from s3\n",
    "    s3c.download_files_in_prefix_to_dir(\n",
    "        config.BASE_CURATION_S3_PREFIX,\n",
    "        config.BASE_CURATION_FOLDER,\n",
    "    )\n",
    "    # download the pretrained model\n",
    "    model_root = pathlib.Path(model_config.load_dir).parent\n",
    "    model_rel_zip = pathlib.Path(model_root, \"relevance_roberta.zip\")\n",
    "\n",
    "    s3c.download_file_from_s3(\n",
    "        model_rel_zip, config.CHECKPOINT_S3_PREFIX, \"relevance_roberta.zip\"\n",
    "    )\n",
    "\n",
    "    with zipfile.ZipFile(pathlib.Path(model_root, \"relevance_roberta.zip\"), \"r\") as z:\n",
    "        z.extractall(model_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: \n",
      " Text \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_config.data_type = \"Text\"\n",
    "print(f\"Data type: \\n {file_config.data_type} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load this model in our pipeline to fine-tune a relevance classifier on our specific ESG curated dataset. For this we have to set the parameter `model_config.load_dir` to be the directory where we saved our first checkpoint. We can check that this is set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NQ checkpoint directory: /opt/app-root/src/aicoe-osc-demo/models/relevance_roberta\n"
     ]
    }
   ],
   "source": [
    "print(f\"NQ checkpoint directory: {model_config.load_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune on curated ESG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the parameters are set, a `FARMTrainer` object can be instantiated by passing all the configuration objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init farm trainer\n",
    "farm_trainer = FARMTrainer(\n",
    "    file_config=file_config,\n",
    "    tokenizer_config=tokenizer_config,\n",
    "    processor_config=processor_config,\n",
    "    model_config=model_config,\n",
    "    training_config=train_config,\n",
    "    mlflow_config=mlflow_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the method `run()` to start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/13/2022 16:02:27 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: True\n",
      "07/13/2022 16:02:27 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'RobertaTokenizer'\n",
      "07/13/2022 16:02:28 - INFO - farm.data_handler.data_silo -   \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "07/13/2022 16:02:28 - INFO - farm.data_handler.data_silo -   Loading train set from: /opt/app-root/src/aicoe-osc-demo/data/kpi_train_split.csv \n",
      "07/13/2022 16:02:28 - INFO - farm.data_handler.data_silo -   Got ya 7 parallel workers to convert 1175 dictionaries to pytorch datasets (chunksize = 34)...\n",
      "07/13/2022 16:02:28 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0 \n",
      "07/13/2022 16:02:28 - INFO - farm.data_handler.data_silo -   /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /|\\\n",
      "07/13/2022 16:02:28 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\  / \\  / \\  /'\\  /'\\\n",
      "07/13/2022 16:02:28 - INFO - farm.data_handler.data_silo -               \n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_train_split.csv:   0%|          | 0/1175 [00:00<?, ? Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/13/2022 16:02:28 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/13/2022 16:02:28 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 3-0\n",
      "Clear Text: \n",
      " \ttext: What is the volume of estimated proven hydrocarbons reserves?\n",
      " \ttext_b: Throughout the year, we have also engaged in dialogue with the investor group Climate Action 100+, and in April 2019 we published a joint statement with this group. The commitments are further addressed in the report and the statement is available at Equinor.com.\n",
      " \ttext_classification_label: 0\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġvolume', 'Ġof', 'Ġestimated', 'Ġproven', 'Ġhydro', 'car', 'bons', 'Ġreserves', '?']\n",
      " \ttokens_b: ['Throughout', 'Ġthe', 'Ġyear', ',', 'Ġwe', 'Ġhave', 'Ġalso', 'Ġengaged', 'Ġin', 'Ġdialogue', 'Ġwith', 'Ġthe', 'Ġinvestor', 'Ġgroup', 'ĠClimate', 'ĠAction', 'Ġ100', '+,', 'Ġand', 'Ġin', 'ĠApril', 'Ġ2019', 'Ġwe', 'Ġpublished', 'Ġa', 'Ġjoint', 'Ġstatement', 'Ġwith', 'Ġthis', 'Ġgroup', '.', 'ĠThe', 'Ġcommitments', 'Ġare', 'Ġfurther', 'Ġaddressed', 'Ġin', 'Ġthe', 'Ġreport', 'Ġand', 'Ġthe', 'Ġstatement', 'Ġis', 'Ġavailable', 'Ġat', 'ĠEqu', 'in', 'or', '.', 'com', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 3149, 9, 2319, 5401, 13575, 5901, 16830, 5880, 116, 2, 2, 36428, 5, 76, 6, 52, 33, 67, 4009, 11, 6054, 19, 5, 3942, 333, 11001, 5828, 727, 30787, 8, 11, 587, 954, 52, 1027, 10, 2660, 445, 19, 42, 333, 4, 20, 9116, 32, 617, 4873, 11, 5, 266, 8, 5, 445, 16, 577, 23, 8510, 179, 368, 4, 175, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [0]\n",
      "_____________________________________________________\n",
      "07/13/2022 16:02:28 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 24-0\n",
      "Clear Text: \n",
      " \ttext: What is the total volume of proven and probable hydrocarbons reserves?\n",
      " \ttext_b: MOL expanded its exploration and production activities to build a broader portfolio in the CEE region when the Romanian Ex-6 Block was awarded to the company in a consortium in 2012. In January, 2013, MOL increased its stake in the Ex-6 Block to 100%. Exploration activities will start with 3D seismic acquisition in 2014. The ratification process for a further 2 blocks (Ex-1 and Ex-5) is in progress. MOL Group's 2013 annual production and divestiture of ZMB and Surgut-7 reduced SPE proved-plus-probable figures of 575.7 MMboe by year-end.\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtotal', 'Ġvolume', 'Ġof', 'Ġproven', 'Ġand', 'Ġprobable', 'Ġhydro', 'car', 'bons', 'Ġreserves', '?']\n",
      " \ttokens_b: ['M', 'OL', 'Ġexpanded', 'Ġits', 'Ġexploration', 'Ġand', 'Ġproduction', 'Ġactivities', 'Ġto', 'Ġbuild', 'Ġa', 'Ġbroader', 'Ġportfolio', 'Ġin', 'Ġthe', 'ĠC', 'EE', 'Ġregion', 'Ġwhen', 'Ġthe', 'ĠRomanian', 'ĠEx', '-', '6', 'ĠBlock', 'Ġwas', 'Ġawarded', 'Ġto', 'Ġthe', 'Ġcompany', 'Ġin', 'Ġa', 'Ġconsortium', 'Ġin', 'Ġ2012', '.', 'ĠIn', 'ĠJanuary', ',', 'Ġ2013', ',', 'ĠM', 'OL', 'Ġincreased', 'Ġits', 'Ġstake', 'Ġin', 'Ġthe', 'ĠEx', '-', '6', 'ĠBlock', 'Ġto', 'Ġ100', '%.', 'ĠExploration', 'Ġactivities', 'Ġwill', 'Ġstart', 'Ġwith', 'Ġ3', 'D', 'Ġseismic', 'Ġacquisition', 'Ġin', 'Ġ2014', '.', 'ĠThe', 'Ġratification', 'Ġprocess', 'Ġfor', 'Ġa', 'Ġfurther', 'Ġ2', 'Ġblocks', 'Ġ(', 'Ex', '-', '1', 'Ġand', 'ĠEx', '-', '5', ')', 'Ġis', 'Ġin', 'Ġprogress', '.', 'ĠM', 'OL', 'ĠGroup', \"'s\", 'Ġ2013', 'Ġannual', 'Ġproduction', 'Ġand', 'Ġdivest', 'iture', 'Ġof', 'ĠZ', 'MB', 'Ġand', 'ĠS', 'urg', 'ut', '-', '7', 'Ġreduced', 'ĠSP', 'E']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 746, 3149, 9, 5401, 8, 15186, 13575, 5901, 16830, 5880, 116, 2, 2, 448, 3384, 4939, 63, 6942, 8, 931, 1713, 7, 1119, 10, 5153, 2819, 11, 5, 230, 9993, 976, 77, 5, 21624, 3015, 12, 401, 11700, 21, 4241, 7, 5, 138, 11, 10, 15918, 11, 1125, 4, 96, 644, 6, 1014, 6, 256, 3384, 1130, 63, 1968, 11, 5, 3015, 12, 401, 11700, 7, 727, 2153, 22949, 1713, 40, 386, 19, 155, 495, 23956, 3857, 11, 777, 4, 20, 34814, 609, 13, 10, 617, 132, 5491, 36, 9089, 12, 134, 8, 3015, 12, 245, 43, 16, 11, 2017, 4, 256, 3384, 826, 18, 1014, 1013, 931, 8, 18374, 19103, 9, 525, 8651, 8, 208, 7150, 1182, 12, 406, 2906, 6178, 717, 2]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_train_split.csv:   3%|▎         | 34/1175 [00:00<00:10, 104.85 Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_train_split.csv:   6%|▌         | 68/1175 [00:00<00:08, 137.44 Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_train_split.csv: 100%|██████████| 1175/1175 [00:03<00:00, 310.53 Dicts/s]\n",
      "07/13/2022 16:02:32 - INFO - farm.data_handler.data_silo -   Loading dev set from: /opt/app-root/src/aicoe-osc-demo/data/kpi_val_split.csv\n",
      "07/13/2022 16:02:32 - INFO - farm.data_handler.data_silo -   Got ya 7 parallel workers to convert 294 dictionaries to pytorch datasets (chunksize = 9)...\n",
      "07/13/2022 16:02:32 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0 \n",
      "07/13/2022 16:02:32 - INFO - farm.data_handler.data_silo -   /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\\n",
      "07/13/2022 16:02:32 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "07/13/2022 16:02:32 - INFO - farm.data_handler.data_silo -               \n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_val_split.csv:   0%|          | 0/294 [00:00<?, ? Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/13/2022 16:02:32 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/13/2022 16:02:32 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 6-0\n",
      "Clear Text: \n",
      " \ttext: What is the base year for carbon reduction commitment?\n",
      " \ttext_b: So we have set new targets. We intend to reduce our carbon emissions at our generation facilities by 55 percent by 2030 and commit to an 80 percent reduction in carbon emissions by 2050.* Both targets are based on a 2005 baseline year. We also intend to lower methane emissions from our natural gas businesses 50 percent by 2030 (as measured against a 2010 baseline).*\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġbase', 'Ġyear', 'Ġfor', 'Ġcarbon', 'Ġreduction', 'Ġcommitment', '?']\n",
      " \ttokens_b: ['So', 'Ġwe', 'Ġhave', 'Ġset', 'Ġnew', 'Ġtargets', '.', 'ĠWe', 'Ġintend', 'Ġto', 'Ġreduce', 'Ġour', 'Ġcarbon', 'Ġemissions', 'Ġat', 'Ġour', 'Ġgeneration', 'Ġfacilities', 'Ġby', 'Ġ55', 'Ġpercent', 'Ġby', 'Ġ2030', 'Ġand', 'Ġcommit', 'Ġto', 'Ġan', 'Ġ80', 'Ġpercent', 'Ġreduction', 'Ġin', 'Ġcarbon', 'Ġemissions', 'Ġby', 'Ġ2050', '.*', 'ĠBoth', 'Ġtargets', 'Ġare', 'Ġbased', 'Ġon', 'Ġa', 'Ġ2005', 'Ġbaseline', 'Ġyear', '.', 'ĠWe', 'Ġalso', 'Ġintend', 'Ġto', 'Ġlower', 'Ġmethane', 'Ġemissions', 'Ġfrom', 'Ġour', 'Ġnatural', 'Ġgas', 'Ġbusinesses', 'Ġ50', 'Ġpercent', 'Ġby', 'Ġ2030', 'Ġ(', 'as', 'Ġmeasured', 'Ġagainst', 'Ġa', 'Ġ2010', 'Ġbaseline', ').', '*']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1542, 76, 13, 4363, 4878, 2720, 116, 2, 2, 2847, 52, 33, 278, 92, 3247, 4, 166, 10557, 7, 1888, 84, 4363, 5035, 23, 84, 2706, 2644, 30, 3490, 135, 30, 12060, 8, 6225, 7, 41, 1812, 135, 4878, 11, 4363, 5035, 30, 24050, 26487, 1868, 3247, 32, 716, 15, 10, 4013, 18043, 76, 4, 166, 67, 10557, 7, 795, 25139, 5035, 31, 84, 1632, 1123, 1252, 654, 135, 30, 12060, 36, 281, 9550, 136, 10, 1824, 18043, 322, 3226, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "07/13/2022 16:02:32 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: In which year was the annual report or the sustainability report published?\n",
      " \ttext_b: Annual Report 2017\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['In', 'Ġwhich', 'Ġyear', 'Ġwas', 'Ġthe', 'Ġannual', 'Ġreport', 'Ġor', 'Ġthe', 'Ġsustainability', 'Ġreport', 'Ġpublished', '?']\n",
      " \ttokens_b: ['Ann', 'ual', 'ĠReport', 'Ġ2017']\n",
      "Features: \n",
      " \tinput_ids: [0, 1121, 61, 76, 21, 5, 1013, 266, 50, 5, 11128, 266, 1027, 116, 2, 2, 20767, 5564, 2872, 193, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_val_split.csv:   3%|▎         | 9/294 [00:00<00:06, 41.79 Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_val_split.csv:   6%|▌         | 18/294 [00:00<00:05, 48.06 Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_val_split.csv: 100%|██████████| 294/294 [00:01<00:00, 153.72 Dicts/s]\n",
      "07/13/2022 16:02:34 - INFO - farm.data_handler.data_silo -   No test set is being loaded\n",
      "07/13/2022 16:02:34 - INFO - farm.data_handler.data_silo -   Examples in train: 1175\n",
      "07/13/2022 16:02:34 - INFO - farm.data_handler.data_silo -   Examples in dev  : 294\n",
      "07/13/2022 16:02:34 - INFO - farm.data_handler.data_silo -   Examples in test : 0\n",
      "07/13/2022 16:02:34 - INFO - farm.data_handler.data_silo -   \n",
      "07/13/2022 16:02:34 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
      "07/13/2022 16:02:34 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 59.07063829787234\n",
      "07/13/2022 16:02:34 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.11148936170212766\n",
      "07/13/2022 16:02:34 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/13/2022 16:02:40 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "07/13/2022 16:02:46 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/13/2022 16:02:46 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/13/2022 16:02:46 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/13/2022 16:02:46 - INFO - farm.modeling.prediction_head -   Loading prediction head from /opt/app-root/src/aicoe-osc-demo/models/relevance_roberta/prediction_head_0.bin\n",
      "07/13/2022 16:02:46 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "07/13/2022 16:02:46 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/13/2022 16:02:46 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 117.5, 'num_training_steps': 1175}'\n",
      "07/13/2022 16:02:46 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0005):   2%|▏         | 29/1175 [00:02<01:23, 13.77it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.24it/s]\n",
      "07/13/2022 16:02:53 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 30 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:02:53 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:02:53 - INFO - farm.eval -   loss: 0.4306248937804796\n",
      "07/13/2022 16:02:53 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:02:53 - INFO - farm.eval -   acc: 0.9115646258503401\n",
      "07/13/2022 16:02:53 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9038    0.6912    0.7833        68\n",
      "           1     0.9132    0.9779    0.9444       226\n",
      "\n",
      "    accuracy                         0.9116       294\n",
      "   macro avg     0.9085    0.8345    0.8639       294\n",
      "weighted avg     0.9111    0.9116    0.9072       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):   5%|▌         | 59/1175 [00:08<01:20, 13.82it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.50it/s]\n",
      "07/13/2022 16:03:00 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 60 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:03:00 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:03:00 - INFO - farm.eval -   loss: 0.6736805750342125\n",
      "07/13/2022 16:03:00 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:03:00 - INFO - farm.eval -   acc: 0.9115646258503401\n",
      "07/13/2022 16:03:00 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    0.7059    0.7869        68\n",
      "           1     0.9167    0.9735    0.9442       226\n",
      "\n",
      "    accuracy                         0.9116       294\n",
      "   macro avg     0.9028    0.8397    0.8655       294\n",
      "weighted avg     0.9102    0.9116    0.9078       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0002):   8%|▊         | 89/1175 [00:15<01:20, 13.52it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.75it/s]\n",
      "07/13/2022 16:03:06 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 90 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:03:06 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:03:06 - INFO - farm.eval -   loss: 0.3965286931018324\n",
      "07/13/2022 16:03:06 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:03:06 - INFO - farm.eval -   acc: 0.935374149659864\n",
      "07/13/2022 16:03:06 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8769    0.8382    0.8571        68\n",
      "           1     0.9520    0.9646    0.9582       226\n",
      "\n",
      "    accuracy                         0.9354       294\n",
      "   macro avg     0.9144    0.9014    0.9077       294\n",
      "weighted avg     0.9346    0.9354    0.9349       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  10%|█         | 119/1175 [00:22<01:16, 13.76it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.16it/s]\n",
      "07/13/2022 16:03:13 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 120 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:03:13 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:03:13 - INFO - farm.eval -   loss: 0.42771484064941845\n",
      "07/13/2022 16:03:13 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:03:13 - INFO - farm.eval -   acc: 0.9115646258503401\n",
      "07/13/2022 16:03:13 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8750    0.7206    0.7903        68\n",
      "           1     0.9202    0.9690    0.9440       226\n",
      "\n",
      "    accuracy                         0.9116       294\n",
      "   macro avg     0.8976    0.8448    0.8671       294\n",
      "weighted avg     0.9097    0.9116    0.9084       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0002):  13%|█▎        | 149/1175 [00:29<01:14, 13.77it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.27it/s]\n",
      "07/13/2022 16:03:20 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 150 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:03:20 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:03:20 - INFO - farm.eval -   loss: 0.38844905504514343\n",
      "07/13/2022 16:03:20 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:03:20 - INFO - farm.eval -   acc: 0.9115646258503401\n",
      "07/13/2022 16:03:20 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7838    0.8529    0.8169        68\n",
      "           1     0.9545    0.9292    0.9417       226\n",
      "\n",
      "    accuracy                         0.9116       294\n",
      "   macro avg     0.8692    0.8911    0.8793       294\n",
      "weighted avg     0.9150    0.9116    0.9128       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0113):  15%|█▌        | 179/1175 [00:35<01:18, 12.75it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.83it/s]\n",
      "07/13/2022 16:03:26 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 180 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:03:26 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:03:26 - INFO - farm.eval -   loss: 0.3938045739035873\n",
      "07/13/2022 16:03:26 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:03:26 - INFO - farm.eval -   acc: 0.9183673469387755\n",
      "07/13/2022 16:03:26 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9231    0.7059    0.8000        68\n",
      "           1     0.9174    0.9823    0.9487       226\n",
      "\n",
      "    accuracy                         0.9184       294\n",
      "   macro avg     0.9202    0.8441    0.8744       294\n",
      "weighted avg     0.9187    0.9184    0.9143       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0003):  18%|█▊        | 209/1175 [00:42<01:13, 13.23it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.90it/s]\n",
      "07/13/2022 16:03:33 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 210 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:03:33 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:03:33 - INFO - farm.eval -   loss: 0.31027339738370974\n",
      "07/13/2022 16:03:33 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:03:33 - INFO - farm.eval -   acc: 0.9455782312925171\n",
      "07/13/2022 16:03:33 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8514    0.9265    0.8873        68\n",
      "           1     0.9773    0.9513    0.9641       226\n",
      "\n",
      "    accuracy                         0.9456       294\n",
      "   macro avg     0.9143    0.9389    0.9257       294\n",
      "weighted avg     0.9481    0.9456    0.9464       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0003):  20%|██        | 239/1175 [00:49<01:07, 13.87it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.26it/s]\n",
      "07/13/2022 16:03:40 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 240 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:03:40 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:03:40 - INFO - farm.eval -   loss: 0.23956977942339572\n",
      "07/13/2022 16:03:40 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:03:40 - INFO - farm.eval -   acc: 0.9591836734693877\n",
      "07/13/2022 16:03:40 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9828    0.8382    0.9048        68\n",
      "           1     0.9534    0.9956    0.9740       226\n",
      "\n",
      "    accuracy                         0.9592       294\n",
      "   macro avg     0.9681    0.9169    0.9394       294\n",
      "weighted avg     0.9602    0.9592    0.9580       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  23%|██▎       | 269/1175 [00:55<01:06, 13.63it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.21it/s]\n",
      "07/13/2022 16:03:46 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 270 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:03:46 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:03:46 - INFO - farm.eval -   loss: 0.20504359937496985\n",
      "07/13/2022 16:03:46 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:03:46 - INFO - farm.eval -   acc: 0.9659863945578231\n",
      "07/13/2022 16:03:46 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9677    0.8824    0.9231        68\n",
      "           1     0.9655    0.9912    0.9782       226\n",
      "\n",
      "    accuracy                         0.9660       294\n",
      "   macro avg     0.9666    0.9368    0.9506       294\n",
      "weighted avg     0.9660    0.9660    0.9654       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0003):  25%|██▌       | 299/1175 [01:02<01:05, 13.41it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 63.93it/s]\n",
      "07/13/2022 16:03:53 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 300 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:03:53 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:03:53 - INFO - farm.eval -   loss: 0.23953444343583927\n",
      "07/13/2022 16:03:53 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:03:53 - INFO - farm.eval -   acc: 0.9625850340136054\n",
      "07/13/2022 16:03:53 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9831    0.8529    0.9134        68\n",
      "           1     0.9574    0.9956    0.9761       226\n",
      "\n",
      "    accuracy                         0.9626       294\n",
      "   macro avg     0.9702    0.9243    0.9448       294\n",
      "weighted avg     0.9634    0.9626    0.9616       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0003):  28%|██▊       | 329/1175 [01:09<01:01, 13.66it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.42it/s]\n",
      "07/13/2022 16:04:00 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 330 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:04:00 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:04:00 - INFO - farm.eval -   loss: 0.11700713541512148\n",
      "07/13/2022 16:04:00 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:04:00 - INFO - farm.eval -   acc: 0.9727891156462585\n",
      "07/13/2022 16:04:00 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9118    0.9394        68\n",
      "           1     0.9739    0.9912    0.9825       226\n",
      "\n",
      "    accuracy                         0.9728       294\n",
      "   macro avg     0.9713    0.9515    0.9609       294\n",
      "weighted avg     0.9727    0.9728    0.9725       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  31%|███       | 359/1175 [01:15<00:59, 13.60it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.84it/s]\n",
      "07/13/2022 16:04:06 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 360 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:04:06 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:04:06 - INFO - farm.eval -   loss: 0.13396853524501567\n",
      "07/13/2022 16:04:06 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:04:06 - INFO - farm.eval -   acc: 0.9727891156462585\n",
      "07/13/2022 16:04:06 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9167    0.9706    0.9429        68\n",
      "           1     0.9910    0.9735    0.9821       226\n",
      "\n",
      "    accuracy                         0.9728       294\n",
      "   macro avg     0.9538    0.9720    0.9625       294\n",
      "weighted avg     0.9738    0.9728    0.9731       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  33%|███▎      | 389/1175 [01:22<00:57, 13.63it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.19it/s]\n",
      "07/13/2022 16:04:13 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 390 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:04:13 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:04:13 - INFO - farm.eval -   loss: 0.2555692848219799\n",
      "07/13/2022 16:04:13 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:04:13 - INFO - farm.eval -   acc: 0.9659863945578231\n",
      "07/13/2022 16:04:13 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9833    0.8676    0.9219        68\n",
      "           1     0.9615    0.9956    0.9783       226\n",
      "\n",
      "    accuracy                         0.9660       294\n",
      "   macro avg     0.9724    0.9316    0.9501       294\n",
      "weighted avg     0.9666    0.9660    0.9652       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  36%|███▌      | 419/1175 [01:29<00:54, 13.88it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.03it/s]\n",
      "07/13/2022 16:04:20 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 420 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:04:20 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:04:20 - INFO - farm.eval -   loss: 0.19877520881566105\n",
      "07/13/2022 16:04:20 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:04:20 - INFO - farm.eval -   acc: 0.9693877551020408\n",
      "07/13/2022 16:04:20 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9836    0.8824    0.9302        68\n",
      "           1     0.9657    0.9956    0.9804       226\n",
      "\n",
      "    accuracy                         0.9694       294\n",
      "   macro avg     0.9746    0.9390    0.9553       294\n",
      "weighted avg     0.9698    0.9694    0.9688       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  38%|███▊      | 449/1175 [01:35<00:55, 13.00it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.36it/s]\n",
      "07/13/2022 16:04:26 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 450 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:04:26 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:04:26 - INFO - farm.eval -   loss: 0.22894696811688067\n",
      "07/13/2022 16:04:26 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:04:26 - INFO - farm.eval -   acc: 0.9659863945578231\n",
      "07/13/2022 16:04:26 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9265    0.9265    0.9265        68\n",
      "           1     0.9779    0.9779    0.9779       226\n",
      "\n",
      "    accuracy                         0.9660       294\n",
      "   macro avg     0.9522    0.9522    0.9522       294\n",
      "weighted avg     0.9660    0.9660    0.9660       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  41%|████      | 479/1175 [01:42<00:51, 13.55it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.48it/s]\n",
      "07/13/2022 16:04:33 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 480 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:04:33 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:04:33 - INFO - farm.eval -   loss: 0.25903675654346914\n",
      "07/13/2022 16:04:33 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:04:33 - INFO - farm.eval -   acc: 0.9693877551020408\n",
      "07/13/2022 16:04:33 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9275    0.9412    0.9343        68\n",
      "           1     0.9822    0.9779    0.9800       226\n",
      "\n",
      "    accuracy                         0.9694       294\n",
      "   macro avg     0.9549    0.9595    0.9572       294\n",
      "weighted avg     0.9696    0.9694    0.9695       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  43%|████▎     | 509/1175 [01:49<00:48, 13.80it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.94it/s]\n",
      "07/13/2022 16:04:40 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 510 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:04:40 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:04:40 - INFO - farm.eval -   loss: 0.25091345551773964\n",
      "07/13/2022 16:04:40 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:04:40 - INFO - farm.eval -   acc: 0.9693877551020408\n",
      "07/13/2022 16:04:40 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9275    0.9412    0.9343        68\n",
      "           1     0.9822    0.9779    0.9800       226\n",
      "\n",
      "    accuracy                         0.9694       294\n",
      "   macro avg     0.9549    0.9595    0.9572       294\n",
      "weighted avg     0.9696    0.9694    0.9695       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 8.9966):  46%|████▌     | 539/1175 [01:55<00:45, 13.93it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.75it/s]\n",
      "07/13/2022 16:04:46 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 540 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:04:46 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:04:46 - INFO - farm.eval -   loss: 0.16675698044818257\n",
      "07/13/2022 16:04:46 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:04:46 - INFO - farm.eval -   acc: 0.9727891156462585\n",
      "07/13/2022 16:04:46 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9286    0.9559    0.9420        68\n",
      "           1     0.9866    0.9779    0.9822       226\n",
      "\n",
      "    accuracy                         0.9728       294\n",
      "   macro avg     0.9576    0.9669    0.9621       294\n",
      "weighted avg     0.9732    0.9728    0.9729       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0002):  48%|████▊     | 569/1175 [02:02<00:45, 13.43it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.67it/s]\n",
      "07/13/2022 16:04:53 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 570 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:04:53 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:04:53 - INFO - farm.eval -   loss: 0.10257335916257262\n",
      "07/13/2022 16:04:53 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:04:53 - INFO - farm.eval -   acc: 0.9829931972789115\n",
      "07/13/2022 16:04:53 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9265    0.9618        68\n",
      "           1     0.9784    1.0000    0.9891       226\n",
      "\n",
      "    accuracy                         0.9830       294\n",
      "   macro avg     0.9892    0.9632    0.9754       294\n",
      "weighted avg     0.9834    0.9830    0.9828       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 4.6709):  51%|█████     | 599/1175 [02:09<00:41, 13.77it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.65it/s]\n",
      "07/13/2022 16:05:00 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 600 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:05:00 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:05:00 - INFO - farm.eval -   loss: 0.033465275407060395\n",
      "07/13/2022 16:05:00 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:05:00 - INFO - farm.eval -   acc: 0.9863945578231292\n",
      "07/13/2022 16:05:00 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9706    0.9706    0.9706        68\n",
      "           1     0.9912    0.9912    0.9912       226\n",
      "\n",
      "    accuracy                         0.9864       294\n",
      "   macro avg     0.9809    0.9809    0.9809       294\n",
      "weighted avg     0.9864    0.9864    0.9864       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  54%|█████▎    | 629/1175 [02:15<00:41, 13.28it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.22it/s]\n",
      "07/13/2022 16:05:06 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 630 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:05:06 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:05:06 - INFO - farm.eval -   loss: 0.022000297193049585\n",
      "07/13/2022 16:05:06 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:05:06 - INFO - farm.eval -   acc: 0.9931972789115646\n",
      "07/13/2022 16:05:06 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9956    0.9956    0.9956       226\n",
      "\n",
      "    accuracy                         0.9932       294\n",
      "   macro avg     0.9904    0.9904    0.9904       294\n",
      "weighted avg     0.9932    0.9932    0.9932       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0003):  56%|█████▌    | 659/1175 [02:22<00:37, 13.81it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.42it/s]\n",
      "07/13/2022 16:05:13 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 660 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:05:13 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:05:13 - INFO - farm.eval -   loss: 0.14665171512670172\n",
      "07/13/2022 16:05:13 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:05:13 - INFO - farm.eval -   acc: 0.9727891156462585\n",
      "07/13/2022 16:05:13 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8947    1.0000    0.9444        68\n",
      "           1     1.0000    0.9646    0.9820       226\n",
      "\n",
      "    accuracy                         0.9728       294\n",
      "   macro avg     0.9474    0.9823    0.9632       294\n",
      "weighted avg     0.9757    0.9728    0.9733       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  59%|█████▊    | 689/1175 [02:29<00:35, 13.71it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.75it/s]\n",
      "07/13/2022 16:05:20 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 690 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:05:20 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:05:20 - INFO - farm.eval -   loss: 0.25742890396537826\n",
      "07/13/2022 16:05:20 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:05:20 - INFO - farm.eval -   acc: 0.95578231292517\n",
      "07/13/2022 16:05:20 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8395    1.0000    0.9128        68\n",
      "           1     1.0000    0.9425    0.9704       226\n",
      "\n",
      "    accuracy                         0.9558       294\n",
      "   macro avg     0.9198    0.9712    0.9416       294\n",
      "weighted avg     0.9629    0.9558    0.9571       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  61%|██████    | 719/1175 [02:35<00:34, 13.24it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.66it/s]\n",
      "07/13/2022 16:05:27 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 720 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:05:27 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:05:27 - INFO - farm.eval -   loss: 0.16492394989111492\n",
      "07/13/2022 16:05:27 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:05:27 - INFO - farm.eval -   acc: 0.9727891156462585\n",
      "07/13/2022 16:05:27 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8947    1.0000    0.9444        68\n",
      "           1     1.0000    0.9646    0.9820       226\n",
      "\n",
      "    accuracy                         0.9728       294\n",
      "   macro avg     0.9474    0.9823    0.9632       294\n",
      "weighted avg     0.9757    0.9728    0.9733       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0002):  64%|██████▎   | 749/1175 [02:42<00:31, 13.59it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.75it/s]\n",
      "07/13/2022 16:05:33 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 750 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:05:33 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:05:33 - INFO - farm.eval -   loss: 0.030513319880606567\n",
      "07/13/2022 16:05:33 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:05:33 - INFO - farm.eval -   acc: 0.9965986394557823\n",
      "07/13/2022 16:05:33 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9853    0.9926        68\n",
      "           1     0.9956    1.0000    0.9978       226\n",
      "\n",
      "    accuracy                         0.9966       294\n",
      "   macro avg     0.9978    0.9926    0.9952       294\n",
      "weighted avg     0.9966    0.9966    0.9966       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  66%|██████▋   | 779/1175 [02:49<00:28, 13.76it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.81it/s]\n",
      "07/13/2022 16:05:40 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 780 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:05:40 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:05:40 - INFO - farm.eval -   loss: 0.03801204401221729\n",
      "07/13/2022 16:05:40 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:05:40 - INFO - farm.eval -   acc: 0.9931972789115646\n",
      "07/13/2022 16:05:40 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9706    0.9851        68\n",
      "           1     0.9912    1.0000    0.9956       226\n",
      "\n",
      "    accuracy                         0.9932       294\n",
      "   macro avg     0.9956    0.9853    0.9903       294\n",
      "weighted avg     0.9933    0.9932    0.9932       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  69%|██████▉   | 809/1175 [02:55<00:26, 13.83it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.09it/s]\n",
      "07/13/2022 16:05:47 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 810 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:05:47 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:05:47 - INFO - farm.eval -   loss: 0.03927462691372428\n",
      "07/13/2022 16:05:47 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:05:47 - INFO - farm.eval -   acc: 0.9931972789115646\n",
      "07/13/2022 16:05:47 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9706    0.9851        68\n",
      "           1     0.9912    1.0000    0.9956       226\n",
      "\n",
      "    accuracy                         0.9932       294\n",
      "   macro avg     0.9956    0.9853    0.9903       294\n",
      "weighted avg     0.9933    0.9932    0.9932       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  71%|███████▏  | 839/1175 [03:02<00:23, 14.09it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.72it/s]\n",
      "07/13/2022 16:05:53 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 840 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:05:53 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:05:53 - INFO - farm.eval -   loss: 0.09073933169679703\n",
      "07/13/2022 16:05:53 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:05:53 - INFO - farm.eval -   acc: 0.9863945578231292\n",
      "07/13/2022 16:05:53 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9412    0.9697        68\n",
      "           1     0.9826    1.0000    0.9912       226\n",
      "\n",
      "    accuracy                         0.9864       294\n",
      "   macro avg     0.9913    0.9706    0.9805       294\n",
      "weighted avg     0.9866    0.9864    0.9862       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  74%|███████▍  | 869/1175 [03:09<00:21, 13.91it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.79it/s]\n",
      "07/13/2022 16:06:00 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 870 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:06:00 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:06:00 - INFO - farm.eval -   loss: 0.07174518844570595\n",
      "07/13/2022 16:06:00 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:06:00 - INFO - farm.eval -   acc: 0.9897959183673469\n",
      "07/13/2022 16:06:00 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9851    0.9706    0.9778        68\n",
      "           1     0.9912    0.9956    0.9934       226\n",
      "\n",
      "    accuracy                         0.9898       294\n",
      "   macro avg     0.9881    0.9831    0.9856       294\n",
      "weighted avg     0.9898    0.9898    0.9898       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  77%|███████▋  | 899/1175 [03:15<00:20, 13.57it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.98it/s]\n",
      "07/13/2022 16:06:07 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 900 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:06:07 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:06:07 - INFO - farm.eval -   loss: 0.07129074615296632\n",
      "07/13/2022 16:06:07 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:06:07 - INFO - farm.eval -   acc: 0.9897959183673469\n",
      "07/13/2022 16:06:07 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9851    0.9706    0.9778        68\n",
      "           1     0.9912    0.9956    0.9934       226\n",
      "\n",
      "    accuracy                         0.9898       294\n",
      "   macro avg     0.9881    0.9831    0.9856       294\n",
      "weighted avg     0.9898    0.9898    0.9898       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  79%|███████▉  | 929/1175 [03:22<00:18, 13.54it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.28it/s]\n",
      "07/13/2022 16:06:13 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 930 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:06:13 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:06:13 - INFO - farm.eval -   loss: 0.07174853838645207\n",
      "07/13/2022 16:06:13 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:06:13 - INFO - farm.eval -   acc: 0.9897959183673469\n",
      "07/13/2022 16:06:13 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9851    0.9706    0.9778        68\n",
      "           1     0.9912    0.9956    0.9934       226\n",
      "\n",
      "    accuracy                         0.9898       294\n",
      "   macro avg     0.9881    0.9831    0.9856       294\n",
      "weighted avg     0.9898    0.9898    0.9898       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  82%|████████▏ | 959/1175 [03:29<00:15, 13.81it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.47it/s]\n",
      "07/13/2022 16:06:20 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 960 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:06:20 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:06:20 - INFO - farm.eval -   loss: 0.058414391000438055\n",
      "07/13/2022 16:06:20 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:06:20 - INFO - farm.eval -   acc: 0.9897959183673469\n",
      "07/13/2022 16:06:20 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9710    0.9853    0.9781        68\n",
      "           1     0.9956    0.9912    0.9933       226\n",
      "\n",
      "    accuracy                         0.9898       294\n",
      "   macro avg     0.9833    0.9882    0.9857       294\n",
      "weighted avg     0.9899    0.9898    0.9898       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  84%|████████▍ | 989/1175 [03:35<00:13, 13.51it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.25it/s]\n",
      "07/13/2022 16:06:27 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 990 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:06:27 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:06:27 - INFO - farm.eval -   loss: 0.0728136435050301\n",
      "07/13/2022 16:06:27 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:06:27 - INFO - farm.eval -   acc: 0.9863945578231292\n",
      "07/13/2022 16:06:27 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.9853    0.9710        68\n",
      "           1     0.9955    0.9867    0.9911       226\n",
      "\n",
      "    accuracy                         0.9864       294\n",
      "   macro avg     0.9763    0.9860    0.9811       294\n",
      "weighted avg     0.9867    0.9864    0.9865       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  87%|████████▋ | 1019/1175 [03:42<00:11, 13.41it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.07it/s]\n",
      "07/13/2022 16:06:33 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1020 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:06:33 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:06:33 - INFO - farm.eval -   loss: 0.0913899213439411\n",
      "07/13/2022 16:06:33 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:06:33 - INFO - farm.eval -   acc: 0.9829931972789115\n",
      "07/13/2022 16:06:33 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9437    0.9853    0.9640        68\n",
      "           1     0.9955    0.9823    0.9889       226\n",
      "\n",
      "    accuracy                         0.9830       294\n",
      "   macro avg     0.9696    0.9838    0.9764       294\n",
      "weighted avg     0.9835    0.9830    0.9831       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  89%|████████▉ | 1049/1175 [03:49<00:09, 13.86it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.78it/s]\n",
      "07/13/2022 16:06:40 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1050 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:06:40 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:06:40 - INFO - farm.eval -   loss: 0.055434639088032\n",
      "07/13/2022 16:06:40 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:06:40 - INFO - farm.eval -   acc: 0.9897959183673469\n",
      "07/13/2022 16:06:40 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9710    0.9853    0.9781        68\n",
      "           1     0.9956    0.9912    0.9933       226\n",
      "\n",
      "    accuracy                         0.9898       294\n",
      "   macro avg     0.9833    0.9882    0.9857       294\n",
      "weighted avg     0.9899    0.9898    0.9898       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  92%|█████████▏| 1079/1175 [03:55<00:07, 13.56it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.53it/s]\n",
      "07/13/2022 16:06:47 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1080 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:06:47 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:06:47 - INFO - farm.eval -   loss: 0.050898706627776846\n",
      "07/13/2022 16:06:47 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:06:47 - INFO - farm.eval -   acc: 0.9931972789115646\n",
      "07/13/2022 16:06:47 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9956    0.9956    0.9956       226\n",
      "\n",
      "    accuracy                         0.9932       294\n",
      "   macro avg     0.9904    0.9904    0.9904       294\n",
      "weighted avg     0.9932    0.9932    0.9932       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  94%|█████████▍| 1109/1175 [04:02<00:04, 13.88it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.93it/s]\n",
      "07/13/2022 16:06:53 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1110 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:06:53 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:06:53 - INFO - farm.eval -   loss: 0.046537887380156684\n",
      "07/13/2022 16:06:53 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:06:53 - INFO - farm.eval -   acc: 0.9931972789115646\n",
      "07/13/2022 16:06:53 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9956    0.9956    0.9956       226\n",
      "\n",
      "    accuracy                         0.9932       294\n",
      "   macro avg     0.9904    0.9904    0.9904       294\n",
      "weighted avg     0.9932    0.9932    0.9932       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  97%|█████████▋| 1139/1175 [04:09<00:02, 13.98it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 65.59it/s]\n",
      "07/13/2022 16:07:00 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1140 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:07:00 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:07:00 - INFO - farm.eval -   loss: 0.04624642345409478\n",
      "07/13/2022 16:07:00 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:07:00 - INFO - farm.eval -   acc: 0.9931972789115646\n",
      "07/13/2022 16:07:00 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9956    0.9956    0.9956       226\n",
      "\n",
      "    accuracy                         0.9932       294\n",
      "   macro avg     0.9904    0.9904    0.9904       294\n",
      "weighted avg     0.9932    0.9932    0.9932       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  99%|█████████▉| 1169/1175 [04:15<00:00, 13.56it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.87it/s]\n",
      "07/13/2022 16:07:07 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1170 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:07:07 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:07:07 - INFO - farm.eval -   loss: 0.04692166913857091\n",
      "07/13/2022 16:07:07 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:07:07 - INFO - farm.eval -   acc: 0.9931972789115646\n",
      "07/13/2022 16:07:07 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9956    0.9956    0.9956       226\n",
      "\n",
      "    accuracy                         0.9932       294\n",
      "   macro avg     0.9904    0.9904    0.9904       294\n",
      "weighted avg     0.9932    0.9932    0.9932       294\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001): 100%|██████████| 1175/1175 [04:20<00:00,  4.50it/s]\n",
      "Evaluating: 100%|██████████| 294/294 [00:04<00:00, 64.68it/s]\n",
      "07/13/2022 16:07:11 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 294 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:07:11 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:07:11 - INFO - farm.eval -   loss: 0.04692222441427679\n",
      "07/13/2022 16:07:11 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:07:11 - INFO - farm.eval -   acc: 0.9931972789115646\n",
      "07/13/2022 16:07:11 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9956    0.9956    0.9956       226\n",
      "\n",
      "    accuracy                         0.9932       294\n",
      "   macro avg     0.9904    0.9904    0.9904       294\n",
      "weighted avg     0.9932    0.9932    0.9932       294\n",
      "\n",
      "07/13/2022 16:07:15 - INFO - src.models.farm_trainer -   Trained model saved to /opt/app-root/src/aicoe-osc-demo/models/RELEVANCE\n",
      "07/13/2022 16:07:15 - INFO - src.models.farm_trainer -   Processor vocabulary saved to /opt/app-root/src/aicoe-osc-demo/models/RELEVANCE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9931972789115646"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farm_trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the training process, the model and the processor vocabulary are saved into the directory `file_config.saved_models_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/app-root/src/aicoe-osc-demo/models/RELEVANCE'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_config.saved_models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 488352\n",
      "drwxrwsr-x. 2 1000630000 1000630000      4096 Jul 12 21:40 .\n",
      "drwxrwsr-x. 6 1000630000 1000630000      4096 Jul 12 21:50 ..\n",
      "-rw-rw-r--. 1 1000630000 1000630000 498669047 Jul 13 16:07 language_model.bin\n",
      "-rw-rw-r--. 1 1000630000 1000630000       562 Jul 13 16:07 language_model_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000    456318 Jul 13 16:07 merges.txt\n",
      "-rw-rw-r--. 1 1000630000 1000630000      7489 Jul 13 16:07 prediction_head_0.bin\n",
      "-rw-rw-r--. 1 1000630000 1000630000       321 Jul 13 16:07 prediction_head_0_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000       735 Jul 13 16:07 processor_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000       772 Jul 13 16:07 special_tokens_map.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000       224 Jul 13 16:07 tokenizer_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000    898822 Jul 13 16:07 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -al $file_config.saved_models_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better estimate the performance of the model on new data, it is recommended to perform k-folds cross validation (CV). CV works as follows:\n",
    "\n",
    "- Split the entire data randomly into k folds (usually 5 to 10)\n",
    "- Fit the model using the K — 1 folds and validate the model using the remaining Kth fold and save the scores\n",
    "- Repeat until every K-fold serve as the test set and average the saved scores\n",
    "\n",
    "`FARMTrainer` includes this features. To perform 3-fold CV proceed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config.run_cv = True\n",
    "train_config.xval_folds = 2\n",
    "train_config.n_epochs = 1\n",
    "train_config.batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_trainer = FARMTrainer(\n",
    "    file_config=file_config,\n",
    "    tokenizer_config=tokenizer_config,\n",
    "    model_config=model_config,\n",
    "    processor_config=processor_config,\n",
    "    training_config=train_config,\n",
    "    mlflow_config=mlflow_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/13/2022 16:07:16 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: True\n",
      "07/13/2022 16:07:16 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'RobertaTokenizer'\n",
      "07/13/2022 16:07:16 - INFO - farm.data_handler.data_silo -   \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "07/13/2022 16:07:16 - INFO - farm.data_handler.data_silo -   Loading train set from: /opt/app-root/src/aicoe-osc-demo/data/kpi_train_split.csv \n",
      "07/13/2022 16:07:17 - INFO - farm.data_handler.data_silo -   Got ya 7 parallel workers to convert 1175 dictionaries to pytorch datasets (chunksize = 34)...\n",
      "07/13/2022 16:07:17 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0 \n",
      "07/13/2022 16:07:17 - INFO - farm.data_handler.data_silo -   /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /|\\\n",
      "07/13/2022 16:07:17 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\  / \\  / \\  /'\\  /'\\\n",
      "07/13/2022 16:07:17 - INFO - farm.data_handler.data_silo -               \n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_train_split.csv:   0%|          | 0/1175 [00:00<?, ? Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/13/2022 16:07:17 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/13/2022 16:07:17 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 2-0\n",
      "Clear Text: \n",
      " \ttext: What is the climate commitment scenario considered?\n",
      " \ttext_b: As a result of our efforts to decrease our exposure to coal-fired generation and increase our portfolio of renewables, energy storage and natural gas capacity, we are significantly reducing our carbon dioxide emissions per megawatt hour (MWh) of generation. In early 2018, we set a target to reduce our carbon intensity, as measured by carbon dioxide emissions per MWh, by 25% from 2016 to 2020 and by 50% by 2030. With the publication of this report, we are increasing the 2030 target from 50% to a 70% reduction of carbon intensity. In a 1.5- 2C Scenario the stress test shows that reductions in carbon intensity would be further accelerated and would avoid additional emissions in our portfolio by 2030 and 2040.\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġclimate', 'Ġcommitment', 'Ġscenario', 'Ġconsidered', '?']\n",
      " \ttokens_b: ['As', 'Ġa', 'Ġresult', 'Ġof', 'Ġour', 'Ġefforts', 'Ġto', 'Ġdecrease', 'Ġour', 'Ġexposure', 'Ġto', 'Ġcoal', '-', 'fired', 'Ġgeneration', 'Ġand', 'Ġincrease', 'Ġour', 'Ġportfolio', 'Ġof', 'Ġrenewables', ',', 'Ġenergy', 'Ġstorage', 'Ġand', 'Ġnatural', 'Ġgas', 'Ġcapacity', ',', 'Ġwe', 'Ġare', 'Ġsignificantly', 'Ġreducing', 'Ġour', 'Ġcarbon', 'Ġdioxide', 'Ġemissions', 'Ġper', 'Ġmeg', 'aw', 'att', 'Ġhour', 'Ġ(', 'M', 'Wh', ')', 'Ġof', 'Ġgeneration', '.', 'ĠIn', 'Ġearly', 'Ġ2018', ',', 'Ġwe', 'Ġset', 'Ġa', 'Ġtarget', 'Ġto', 'Ġreduce', 'Ġour', 'Ġcarbon', 'Ġintensity', ',', 'Ġas', 'Ġmeasured', 'Ġby', 'Ġcarbon', 'Ġdioxide', 'Ġemissions', 'Ġper', 'ĠM', 'Wh', ',', 'Ġby', 'Ġ25', '%', 'Ġfrom', 'Ġ2016', 'Ġto', 'Ġ2020', 'Ġand', 'Ġby', 'Ġ50', '%', 'Ġby', 'Ġ2030', '.', 'ĠWith', 'Ġthe', 'Ġpublication', 'Ġof', 'Ġthis', 'Ġreport', ',', 'Ġwe', 'Ġare', 'Ġincreasing', 'Ġthe', 'Ġ2030', 'Ġtarget', 'Ġfrom', 'Ġ50', '%', 'Ġto', 'Ġa', 'Ġ70', '%', 'Ġreduction', 'Ġof', 'Ġcarbon', 'Ġintensity', '.', 'ĠIn', 'Ġa', 'Ġ1', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 2147, 2720, 5665, 1687, 116, 2, 2, 1620, 10, 898, 9, 84, 1170, 7, 7280, 84, 4895, 7, 4051, 12, 15361, 2706, 8, 712, 84, 2819, 9, 26618, 6, 1007, 3521, 8, 1632, 1123, 2148, 6, 52, 32, 3625, 4881, 84, 4363, 15746, 5035, 228, 10721, 1584, 2611, 1946, 36, 448, 14447, 43, 9, 2706, 4, 96, 419, 199, 6, 52, 278, 10, 1002, 7, 1888, 84, 4363, 10603, 6, 25, 9550, 30, 4363, 15746, 5035, 228, 256, 14447, 6, 30, 564, 207, 31, 336, 7, 2760, 8, 30, 654, 207, 30, 12060, 4, 590, 5, 5362, 9, 42, 266, 6, 52, 32, 2284, 5, 12060, 1002, 31, 654, 207, 7, 10, 1510, 207, 4878, 9, 4363, 10603, 4, 96, 10, 112, 4, 2]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "07/13/2022 16:07:17 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 32-0\n",
      "Clear Text: \n",
      " \ttext: What is the volume of estimated proven hydrocarbons reserves?\n",
      " \ttext_b: As in previous years, Rosneft tops the list of the world's public companies in terms of proven (1P) SEC reserves, with 39,907 mboe20 of hydrocarbon reserves at the end of 2017 and the reserves-to-production ratio of roughly 20 years.\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġvolume', 'Ġof', 'Ġestimated', 'Ġproven', 'Ġhydro', 'car', 'bons', 'Ġreserves', '?']\n",
      " \ttokens_b: ['As', 'Ġin', 'Ġprevious', 'Ġyears', ',', 'ĠRos', 'ne', 'ft', 'Ġtops', 'Ġthe', 'Ġlist', 'Ġof', 'Ġthe', 'Ġworld', \"'s\", 'Ġpublic', 'Ġcompanies', 'Ġin', 'Ġterms', 'Ġof', 'Ġproven', 'Ġ(', '1', 'P', ')', 'ĠSEC', 'Ġreserves', ',', 'Ġwith', 'Ġ39', ',', '9', '07', 'Ġm', 'bo', 'e', '20', 'Ġof', 'Ġhydro', 'carbon', 'Ġreserves', 'Ġat', 'Ġthe', 'Ġend', 'Ġof', 'Ġ2017', 'Ġand', 'Ġthe', 'Ġreserves', '-', 'to', '-', 'production', 'Ġratio', 'Ġof', 'Ġroughly', 'Ġ20', 'Ġyears', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 3149, 9, 2319, 5401, 13575, 5901, 16830, 5880, 116, 2, 2, 1620, 11, 986, 107, 6, 4168, 858, 2543, 13657, 5, 889, 9, 5, 232, 18, 285, 451, 11, 1110, 9, 5401, 36, 134, 510, 43, 3614, 5880, 6, 19, 3191, 6, 466, 3570, 475, 3983, 242, 844, 9, 13575, 23612, 5880, 23, 5, 253, 9, 193, 8, 5, 5880, 12, 560, 12, 22862, 1750, 9, 3667, 291, 107, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_train_split.csv: 100%|██████████| 1175/1175 [00:03<00:00, 316.64 Dicts/s]\n",
      "07/13/2022 16:07:20 - INFO - farm.data_handler.data_silo -   Loading dev set from: /opt/app-root/src/aicoe-osc-demo/data/kpi_val_split.csv\n",
      "07/13/2022 16:07:21 - INFO - farm.data_handler.data_silo -   Got ya 7 parallel workers to convert 294 dictionaries to pytorch datasets (chunksize = 9)...\n",
      "07/13/2022 16:07:21 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0 \n",
      "07/13/2022 16:07:21 - INFO - farm.data_handler.data_silo -   /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\\n",
      "07/13/2022 16:07:21 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "07/13/2022 16:07:21 - INFO - farm.data_handler.data_silo -               \n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_val_split.csv:   0%|          | 0/294 [00:00<?, ? Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/13/2022 16:07:21 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/13/2022 16:07:21 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 1-0\n",
      "Clear Text: \n",
      " \ttext: What is the base year for carbon reduction commitment?\n",
      " \ttext_b: The Group intends to reduce its carbon intensity by 15% between 2015, the date of the Paris agreement, and 2030. This undertaking represents a responsible contribution by TOTAL to the Paris agreement targets and it also enables the Group to fulfill its mission to supply to as many people as possible a more affordable, more available and cleaner energy.\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġbase', 'Ġyear', 'Ġfor', 'Ġcarbon', 'Ġreduction', 'Ġcommitment', '?']\n",
      " \ttokens_b: ['The', 'ĠGroup', 'Ġintends', 'Ġto', 'Ġreduce', 'Ġits', 'Ġcarbon', 'Ġintensity', 'Ġby', 'Ġ15', '%', 'Ġbetween', 'Ġ2015', ',', 'Ġthe', 'Ġdate', 'Ġof', 'Ġthe', 'ĠParis', 'Ġagreement', ',', 'Ġand', 'Ġ2030', '.', 'ĠThis', 'Ġundertaking', 'Ġrepresents', 'Ġa', 'Ġresponsible', 'Ġcontribution', 'Ġby', 'ĠTOTAL', 'Ġto', 'Ġthe', 'ĠParis', 'Ġagreement', 'Ġtargets', 'Ġand', 'Ġit', 'Ġalso', 'Ġenables', 'Ġthe', 'ĠGroup', 'Ġto', 'Ġfulfill', 'Ġits', 'Ġmission', 'Ġto', 'Ġsupply', 'Ġto', 'Ġas', 'Ġmany', 'Ġpeople', 'Ġas', 'Ġpossible', 'Ġa', 'Ġmore', 'Ġaffordable', ',', 'Ġmore', 'Ġavailable', 'Ġand', 'Ġcleaner', 'Ġenergy', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1542, 76, 13, 4363, 4878, 2720, 116, 2, 2, 133, 826, 9731, 7, 1888, 63, 4363, 10603, 30, 379, 207, 227, 570, 6, 5, 1248, 9, 5, 2201, 1288, 6, 8, 12060, 4, 152, 17963, 3372, 10, 2149, 5883, 30, 36575, 7, 5, 2201, 1288, 3247, 8, 24, 67, 9849, 5, 826, 7, 14235, 63, 2511, 7, 1787, 7, 25, 171, 82, 25, 678, 10, 55, 4555, 6, 55, 577, 8, 16126, 1007, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "07/13/2022 16:07:21 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 8-0\n",
      "Clear Text: \n",
      " \ttext: What is the total volume of hydrocarbons production?\n",
      " \ttext_b: Production in 2016 averaged 118.2 mboepd, including full-year production from BP Norge legacy assets. 77 per cent was liquids and 23 per cent was gas. This represents a substantial increase compared to 60.0 mboepd in 2015, mostly due to the inclusion of additional producing assets through the merger with BP Norge. For Det norske legacy assets, the production increased to 63.5 mboepd in 2016.\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtotal', 'Ġvolume', 'Ġof', 'Ġhydro', 'car', 'bons', 'Ġproduction', '?']\n",
      " \ttokens_b: ['Production', 'Ġin', 'Ġ2016', 'Ġaveraged', 'Ġ118', '.', '2', 'Ġm', 'bo', 'ep', 'd', ',', 'Ġincluding', 'Ġfull', '-', 'year', 'Ġproduction', 'Ġfrom', 'ĠBP', 'ĠN', 'orge', 'Ġlegacy', 'Ġassets', '.', 'Ġ77', 'Ġper', 'Ġcent', 'Ġwas', 'Ġliquids', 'Ġand', 'Ġ23', 'Ġper', 'Ġcent', 'Ġwas', 'Ġgas', '.', 'ĠThis', 'Ġrepresents', 'Ġa', 'Ġsubstantial', 'Ġincrease', 'Ġcompared', 'Ġto', 'Ġ60', '.', '0', 'Ġm', 'bo', 'ep', 'd', 'Ġin', 'Ġ2015', ',', 'Ġmostly', 'Ġdue', 'Ġto', 'Ġthe', 'Ġinclusion', 'Ġof', 'Ġadditional', 'Ġproducing', 'Ġassets', 'Ġthrough', 'Ġthe', 'Ġmerger', 'Ġwith', 'ĠBP', 'ĠN', 'orge', '.', 'ĠFor', 'ĠDet', 'Ġn', 'ors', 'ke', 'Ġlegacy', 'Ġassets', ',', 'Ġthe', 'Ġproduction', 'Ġincreased', 'Ġto', 'Ġ63', '.', '5', 'Ġm', 'bo', 'ep', 'd', 'Ġin', 'Ġ2016', '.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 746, 3149, 9, 13575, 5901, 16830, 931, 116, 2, 2, 43306, 11, 336, 8329, 16970, 4, 176, 475, 3983, 2462, 417, 6, 217, 455, 12, 180, 931, 31, 12184, 234, 26875, 5184, 1781, 4, 6791, 228, 715, 21, 26140, 8, 883, 228, 715, 21, 1123, 4, 152, 3372, 10, 6143, 712, 1118, 7, 1191, 4, 288, 475, 3983, 2462, 417, 11, 570, 6, 2260, 528, 7, 5, 9290, 9, 943, 5591, 1781, 149, 5, 7394, 19, 12184, 234, 26875, 4, 286, 11185, 295, 994, 1071, 5184, 1781, 6, 5, 931, 1130, 7, 5549, 4, 245, 475, 3983, 2462, 417, 11, 336, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_val_split.csv:   3%|▎         | 9/294 [00:00<00:12, 23.53 Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo/data/kpi_val_split.csv: 100%|██████████| 294/294 [00:01<00:00, 147.01 Dicts/s]\n",
      "07/13/2022 16:07:23 - INFO - farm.data_handler.data_silo -   No test set is being loaded\n",
      "07/13/2022 16:07:23 - INFO - farm.data_handler.data_silo -   Examples in train: 1175\n",
      "07/13/2022 16:07:23 - INFO - farm.data_handler.data_silo -   Examples in dev  : 294\n",
      "07/13/2022 16:07:23 - INFO - farm.data_handler.data_silo -   Examples in test : 0\n",
      "07/13/2022 16:07:23 - INFO - farm.data_handler.data_silo -   \n",
      "07/13/2022 16:07:23 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
      "07/13/2022 16:07:23 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 59.07063829787234\n",
      "07/13/2022 16:07:23 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.11148936170212766\n",
      "07/13/2022 16:07:23 - INFO - src.models.farm_trainer -   ############ Crossvalidation: Fold 0 ############\n",
      "07/13/2022 16:07:23 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/13/2022 16:07:26 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "07/13/2022 16:07:29 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/13/2022 16:07:29 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/13/2022 16:07:29 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/13/2022 16:07:29 - INFO - farm.modeling.prediction_head -   Loading prediction head from /opt/app-root/src/aicoe-osc-demo/models/relevance_roberta/prediction_head_0.bin\n",
      "07/13/2022 16:07:29 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "07/13/2022 16:07:29 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/13/2022 16:07:29 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 7.4, 'num_training_steps': 74}'\n",
      "07/13/2022 16:07:30 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0201):  41%|████      | 30/74 [00:02<00:04, 10.78it/s]\n",
      "Evaluating: 100%|██████████| 19/19 [00:00<00:00, 50.99it/s]\n",
      "07/13/2022 16:07:33 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 30 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:07:33 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:07:33 - INFO - farm.eval -   loss: 0.037622360748634356\n",
      "07/13/2022 16:07:33 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:07:33 - INFO - farm.eval -   acc: 0.9794520547945206\n",
      "07/13/2022 16:07:33 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9444    0.9714    0.9577        35\n",
      "           1     0.9909    0.9820    0.9864       111\n",
      "\n",
      "    accuracy                         0.9795       146\n",
      "   macro avg     0.9677    0.9767    0.9721       146\n",
      "weighted avg     0.9798    0.9795    0.9796       146\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.5546):  81%|████████  | 60/74 [00:06<00:01, 11.10it/s]\n",
      "Evaluating: 100%|██████████| 19/19 [00:00<00:00, 50.75it/s]\n",
      "07/13/2022 16:07:36 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 60 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:07:36 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:07:36 - INFO - farm.eval -   loss: 0.09740949746489219\n",
      "07/13/2022 16:07:36 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:07:36 - INFO - farm.eval -   acc: 0.9794520547945206\n",
      "07/13/2022 16:07:36 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9211    1.0000    0.9589        35\n",
      "           1     1.0000    0.9730    0.9863       111\n",
      "\n",
      "    accuracy                         0.9795       146\n",
      "   macro avg     0.9605    0.9865    0.9726       146\n",
      "weighted avg     0.9811    0.9795    0.9797       146\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.5629): 100%|██████████| 74/74 [00:07<00:00,  9.53it/s]\n",
      "Evaluating: 100%|██████████| 92/92 [00:01<00:00, 50.32it/s]\n",
      "07/13/2022 16:07:39 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | TEST SET | AFTER 74 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:07:39 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:07:39 - INFO - farm.eval -   loss: 0.1138055232024061\n",
      "07/13/2022 16:07:39 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:07:39 - INFO - farm.eval -   acc: 0.9741496598639455\n",
      "07/13/2022 16:07:39 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9365    0.9620    0.9491       184\n",
      "           1     0.9872    0.9782    0.9827       551\n",
      "\n",
      "    accuracy                         0.9741       735\n",
      "   macro avg     0.9618    0.9701    0.9659       735\n",
      "weighted avg     0.9745    0.9741    0.9743       735\n",
      "\n",
      "Evaluating: 100%|██████████| 92/92 [00:01<00:00, 50.46it/s]\n",
      "07/13/2022 16:07:41 - INFO - src.models.farm_trainer -   ############ Crossvalidation: Fold 1 ############\n",
      "07/13/2022 16:07:41 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/13/2022 16:07:44 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "07/13/2022 16:07:47 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/13/2022 16:07:47 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/13/2022 16:07:47 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/13/2022 16:07:47 - INFO - farm.modeling.prediction_head -   Loading prediction head from /opt/app-root/src/aicoe-osc-demo/models/relevance_roberta/prediction_head_0.bin\n",
      "07/13/2022 16:07:47 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "07/13/2022 16:07:47 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/13/2022 16:07:47 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 7.4, 'num_training_steps': 74}'\n",
      "07/13/2022 16:07:48 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0317):  41%|████      | 30/74 [00:02<00:04, 10.71it/s]\n",
      "Evaluating: 100%|██████████| 19/19 [00:00<00:00, 50.94it/s]\n",
      "07/13/2022 16:07:51 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 30 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:07:51 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:07:51 - INFO - farm.eval -   loss: 0.15208220560433103\n",
      "07/13/2022 16:07:51 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:07:51 - INFO - farm.eval -   acc: 0.9523809523809523\n",
      "07/13/2022 16:07:51 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7879    0.8814        33\n",
      "           1     0.9421    1.0000    0.9702       114\n",
      "\n",
      "    accuracy                         0.9524       147\n",
      "   macro avg     0.9711    0.8939    0.9258       147\n",
      "weighted avg     0.9551    0.9524    0.9503       147\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0009):  81%|████████  | 60/74 [00:06<00:01, 10.91it/s]\n",
      "Evaluating: 100%|██████████| 19/19 [00:00<00:00, 50.69it/s]\n",
      "07/13/2022 16:07:54 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 60 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:07:54 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:07:54 - INFO - farm.eval -   loss: 0.4864911469654655\n",
      "07/13/2022 16:07:54 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:07:54 - INFO - farm.eval -   acc: 0.9319727891156463\n",
      "07/13/2022 16:07:54 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.6970    0.8214        33\n",
      "           1     0.9194    1.0000    0.9580       114\n",
      "\n",
      "    accuracy                         0.9320       147\n",
      "   macro avg     0.9597    0.8485    0.8897       147\n",
      "weighted avg     0.9375    0.9320    0.9273       147\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0004): 100%|██████████| 74/74 [00:07<00:00,  9.45it/s]\n",
      "Evaluating: 100%|██████████| 92/92 [00:01<00:00, 50.37it/s]\n",
      "07/13/2022 16:07:57 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | TEST SET | AFTER 74 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/13/2022 16:07:57 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/13/2022 16:07:57 - INFO - farm.eval -   loss: 0.21988373640950068\n",
      "07/13/2022 16:07:57 - INFO - farm.eval -   task_name: text_classification\n",
      "07/13/2022 16:07:57 - INFO - farm.eval -   acc: 0.9632152588555858\n",
      "07/13/2022 16:07:57 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8533    0.9208       184\n",
      "           1     0.9532    1.0000    0.9760       550\n",
      "\n",
      "    accuracy                         0.9632       734\n",
      "   macro avg     0.9766    0.9266    0.9484       734\n",
      "weighted avg     0.9649    0.9632    0.9622       734\n",
      "\n",
      "Evaluating: 100%|██████████| 92/92 [00:01<00:00, 50.52it/s]\n",
      "07/13/2022 16:07:59 - INFO - src.models.farm_trainer -   ############ RESULT_CV -- 2 folds ############\n",
      "07/13/2022 16:07:59 - INFO - src.models.farm_trainer -   Mean F1:  97.9, std F1: 0.003\n",
      "07/13/2022 16:07:59 - INFO - src.models.farm_trainer -   Mean recall:  97.0, std recall: 0.017\n",
      "07/13/2022 16:07:59 - INFO - src.models.farm_trainer -   Mean accuracy:  96.9, std accuracy; 0.005\n",
      "07/13/2022 16:07:59 - INFO - src.models.farm_trainer -   Mean precision:  98.9, std  precision: 0.011\n"
     ]
    }
   ],
   "source": [
    "farm_trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** CV mode does not save a checkpoint, it is only used for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Metrics\n",
    "\n",
    "In this section, we will quantify the performance of the fine tuned model on our dataset. Specifically, we will calculate the precision, recall, and f1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>In which year was the annual report or the sus...</td>\n",
       "      <td>Annual Report 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the base year for carbon reduction com...</td>\n",
       "      <td>The Group intends to reduce its carbon intensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the volume of estimated proven hydroca...</td>\n",
       "      <td>OMV had proven reserves of approximately 1.03 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the target carbon reduction in percent...</td>\n",
       "      <td>The objective for 2025 is to reduce upstream e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the volume of estimated proven hydroca...</td>\n",
       "      <td>As of December 31, 2015, TOTAL's combined prov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "59        1  In which year was the annual report or the sus...   \n",
       "287       1  What is the base year for carbon reduction com...   \n",
       "1420      1  What is the volume of estimated proven hydroca...   \n",
       "631       1  What is the target carbon reduction in percent...   \n",
       "1395      1  What is the volume of estimated proven hydroca...   \n",
       "\n",
       "                                                 text_b  \n",
       "59                                   Annual Report 2017  \n",
       "287   The Group intends to reduce its carbon intensi...  \n",
       "1420  OMV had proven reserves of approximately 1.03 ...  \n",
       "631   The objective for 2025 is to reduce upstream e...  \n",
       "1395  As of December 31, 2015, TOTAL's combined prov...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test set\n",
    "test_data = pd.read_csv(file_config.dev_filename, index_col=0)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/13/2022 16:07:59 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "07/13/2022 16:08:02 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/13/2022 16:08:02 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/13/2022 16:08:02 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/13/2022 16:08:02 - INFO - farm.modeling.prediction_head -   Loading prediction head from /opt/app-root/src/aicoe-osc-demo/models/RELEVANCE/prediction_head_0.bin\n",
      "07/13/2022 16:08:02 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'RobertaTokenizer'\n",
      "07/13/2022 16:08:02 - INFO - farm.data_handler.processor -   Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "07/13/2022 16:08:02 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "07/13/2022 16:08:03 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "07/13/2022 16:08:03 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "07/13/2022 16:08:03 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "07/13/2022 16:08:03 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "07/13/2022 16:08:03 - INFO - farm.infer -               \n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/13/2022 16:08:03 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/13/2022 16:08:03 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 4-0\n",
      "Clear Text: \n",
      " \ttext: What is the volume of estimated proven hydrocarbons reserves?\n",
      " \ttext_b: As of December 31, 2015, TOTAL's combined proved reserves of oil and gas were 11,580 Mboe (53% of which were proved developed reserves) compared to 11, 523 Mboe (50% of which were proved developed reserves) as of December 31, 2014. Liquids (crude oil, condensates, natural gas liquids and bitumen) at year-end 2015 represented approximately 48% of these reserves and natural gas the remaining 52% and, at year-end 2014, approximately 46% of these reserves and natural gas the remaining 54%.\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġvolume', 'Ġof', 'Ġestimated', 'Ġproven', 'Ġhydro', 'car', 'bons', 'Ġreserves', '?']\n",
      " \ttokens_b: ['As', 'Ġof', 'ĠDecember', 'Ġ31', ',', 'Ġ2015', ',', 'ĠTOTAL', \"'s\", 'Ġcombined', 'Ġproved', 'Ġreserves', 'Ġof', 'Ġoil', 'Ġand', 'Ġgas', 'Ġwere', 'Ġ11', ',', '580', 'ĠM', 'bo', 'e', 'Ġ(', '53', '%', 'Ġof', 'Ġwhich', 'Ġwere', 'Ġproved', 'Ġdeveloped', 'Ġreserves', ')', 'Ġcompared', 'Ġto', 'Ġ11', ',', 'Ġ5', '23', 'ĠM', 'bo', 'e', 'Ġ(', '50', '%', 'Ġof', 'Ġwhich', 'Ġwere', 'Ġproved', 'Ġdeveloped', 'Ġreserves', ')', 'Ġas', 'Ġof', 'ĠDecember', 'Ġ31', ',', 'Ġ2014', '.', 'ĠLiqu', 'ids', 'Ġ(', 'cr', 'ude', 'Ġoil', ',', 'Ġcond', 'ens', 'ates', ',', 'Ġnatural', 'Ġgas', 'Ġliquids', 'Ġand', 'Ġbit', 'umen', ')', 'Ġat', 'Ġyear', '-', 'end', 'Ġ2015', 'Ġrepresented', 'Ġapproximately', 'Ġ48', '%', 'Ġof', 'Ġthese', 'Ġreserves', 'Ġand', 'Ġnatural', 'Ġgas', 'Ġthe', 'Ġremaining', 'Ġ52', '%', 'Ġand', ',', 'Ġat', 'Ġyear', '-', 'end', 'Ġ2014', ',', 'Ġapproximately', 'Ġ46', '%', 'Ġof', 'Ġthese', 'Ġreserves', 'Ġand', 'Ġnatural', 'Ġgas', 'Ġthe', 'Ġremaining', 'Ġ54', '%.']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 3149, 9, 2319, 5401, 13575, 5901, 16830, 5880, 116, 2, 2, 1620, 9, 719, 1105, 6, 570, 6, 36575, 18, 2771, 4362, 5880, 9, 681, 8, 1123, 58, 365, 6, 31663, 256, 3983, 242, 36, 4540, 207, 9, 61, 58, 4362, 2226, 5880, 43, 1118, 7, 365, 6, 195, 1922, 256, 3983, 242, 36, 1096, 207, 9, 61, 58, 4362, 2226, 5880, 43, 25, 9, 719, 1105, 6, 777, 4, 26185, 7823, 36, 8344, 6343, 681, 6, 10022, 1290, 1626, 6, 1632, 1123, 26140, 8, 828, 18546, 43, 23, 76, 12, 1397, 570, 4625, 2219, 2929, 207, 9, 209, 5880, 8, 1632, 1123, 5, 2405, 3135, 207, 8, 6, 23, 76, 12, 1397, 777, 6, 2219, 4059, 207, 9, 209, 5880, 8, 1632, 1123, 5, 2405, 4431, 2153, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "07/13/2022 16:08:03 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: In which year was the annual report or the sustainability report published?\n",
      " \ttext_b: Annual Report 2017\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['In', 'Ġwhich', 'Ġyear', 'Ġwas', 'Ġthe', 'Ġannual', 'Ġreport', 'Ġor', 'Ġthe', 'Ġsustainability', 'Ġreport', 'Ġpublished', '?']\n",
      " \ttokens_b: ['Ann', 'ual', 'ĠReport', 'Ġ2017']\n",
      "Features: \n",
      " \tinput_ids: [0, 1121, 61, 76, 21, 5, 1013, 266, 50, 5, 11128, 266, 1027, 116, 2, 2, 20767, 5564, 2872, 193, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Inferencing Samples:   0%|          | 0/3 [00:00<?, ? Batches/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:04<00:00,  1.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.62 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.64 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.63 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.52 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.63 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.68 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.62 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.48 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.63 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.65 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.60 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.61 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.62 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.66 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.65 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.31 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.62 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.62 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.63 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.48 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.64 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.64 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.58 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:02<00:00,  1.48 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.63 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.65 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.62 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.60 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.62 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.66 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.65 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.58 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "# get predictions from current model\n",
    "model = Inferencer.load(file_config.saved_models_dir)\n",
    "\n",
    "result = model.inference_from_file(file_config.dev_filename)\n",
    "results = [d for r in result for d in r[\"predictions\"]]\n",
    "preds = [int(r[\"label\"]) for r in results]\n",
    "\n",
    "test_data[\"pred\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalute performance\n",
    "groups = test_data.groupby(\"text\")\n",
    "scores = {}\n",
    "for group, data in groups:\n",
    "    pred = data.pred\n",
    "    true = data.label\n",
    "    scores[group] = {}\n",
    "    scores[group][\"accuracy\"] = accuracy_score(true, pred)\n",
    "    scores[group][\"f1_score\"] = f1_score(true, pred)\n",
    "    scores[group][\"recall_score\"] = recall_score(true, pred)\n",
    "    scores[group][\"precision_score\"] = precision_score(true, pred)\n",
    "    scores[group][\"support\"] = len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>In which year was the annual report or the sustainability report published?</th>\n",
       "      <th>What is the annual total production from coal?</th>\n",
       "      <th>What is the base year for carbon reduction commitment?</th>\n",
       "      <th>What is the climate commitment scenario considered?</th>\n",
       "      <th>What is the company name?</th>\n",
       "      <th>What is the target carbon reduction in percentage?</th>\n",
       "      <th>What is the target year for climate commitment?</th>\n",
       "      <th>What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?</th>\n",
       "      <th>What is the total amount of energy indirect greenhouse gases emissions referred to as scope 2 emissions?</th>\n",
       "      <th>What is the total amount of scope 1 and 2 greenhouse gases emissions?</th>\n",
       "      <th>What is the total amount of scope 1, scope 2 and scope 3 greenhouse gases emissions?</th>\n",
       "      <th>What is the total amount of upstream energy indirect greenhouse gases emissions referred to as scope 3 emissions?</th>\n",
       "      <th>What is the total installed capacity from coal?</th>\n",
       "      <th>What is the total volume of crude oil liquid production?</th>\n",
       "      <th>What is the total volume of hydrocarbons production?</th>\n",
       "      <th>What is the total volume of natural gas liquid production?</th>\n",
       "      <th>What is the total volume of natural gas production?</th>\n",
       "      <th>What is the total volume of proven and probable hydrocarbons reserves?</th>\n",
       "      <th>What is the volume of estimated proven hydrocarbons reserves?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 In which year was the annual report or the sustainability report published?  \\\n",
       "accuracy                                                       1.0                             \n",
       "f1_score                                                       1.0                             \n",
       "recall_score                                                   1.0                             \n",
       "precision_score                                                1.0                             \n",
       "support                                                       39.0                             \n",
       "\n",
       "                 What is the annual total production from coal?  \\\n",
       "accuracy                                                    1.0   \n",
       "f1_score                                                    1.0   \n",
       "recall_score                                                1.0   \n",
       "precision_score                                             1.0   \n",
       "support                                                     5.0   \n",
       "\n",
       "                 What is the base year for carbon reduction commitment?  \\\n",
       "accuracy                                                       1.0        \n",
       "f1_score                                                       1.0        \n",
       "recall_score                                                   1.0        \n",
       "precision_score                                                1.0        \n",
       "support                                                       18.0        \n",
       "\n",
       "                 What is the climate commitment scenario considered?  \\\n",
       "accuracy                                                  0.960000     \n",
       "f1_score                                                  0.971429     \n",
       "recall_score                                              1.000000     \n",
       "precision_score                                           0.944444     \n",
       "support                                                  25.000000     \n",
       "\n",
       "                 What is the company name?  \\\n",
       "accuracy                          0.971429   \n",
       "f1_score                          0.981132   \n",
       "recall_score                      0.962963   \n",
       "precision_score                   1.000000   \n",
       "support                          35.000000   \n",
       "\n",
       "                 What is the target carbon reduction in percentage?  \\\n",
       "accuracy                                                       1.0    \n",
       "f1_score                                                       1.0    \n",
       "recall_score                                                   1.0    \n",
       "precision_score                                                1.0    \n",
       "support                                                       22.0    \n",
       "\n",
       "                 What is the target year for climate commitment?  \\\n",
       "accuracy                                                     1.0   \n",
       "f1_score                                                     1.0   \n",
       "recall_score                                                 1.0   \n",
       "precision_score                                              1.0   \n",
       "support                                                     28.0   \n",
       "\n",
       "                 What is the total amount of direct greenhouse gases emissions referred to as scope 1 emissions?  \\\n",
       "accuracy                                                       1.0                                                 \n",
       "f1_score                                                       1.0                                                 \n",
       "recall_score                                                   1.0                                                 \n",
       "precision_score                                                1.0                                                 \n",
       "support                                                       13.0                                                 \n",
       "\n",
       "                 What is the total amount of energy indirect greenhouse gases emissions referred to as scope 2 emissions?  \\\n",
       "accuracy                                                       1.0                                                          \n",
       "f1_score                                                       1.0                                                          \n",
       "recall_score                                                   1.0                                                          \n",
       "precision_score                                                1.0                                                          \n",
       "support                                                        9.0                                                          \n",
       "\n",
       "                 What is the total amount of scope 1 and 2 greenhouse gases emissions?  \\\n",
       "accuracy                                                       1.0                       \n",
       "f1_score                                                       1.0                       \n",
       "recall_score                                                   1.0                       \n",
       "precision_score                                                1.0                       \n",
       "support                                                        2.0                       \n",
       "\n",
       "                 What is the total amount of scope 1, scope 2 and scope 3 greenhouse gases emissions?  \\\n",
       "accuracy                                                       1.0                                      \n",
       "f1_score                                                       1.0                                      \n",
       "recall_score                                                   1.0                                      \n",
       "precision_score                                                1.0                                      \n",
       "support                                                        1.0                                      \n",
       "\n",
       "                 What is the total amount of upstream energy indirect greenhouse gases emissions referred to as scope 3 emissions?  \\\n",
       "accuracy                                                       1.0                                                                   \n",
       "f1_score                                                       1.0                                                                   \n",
       "recall_score                                                   1.0                                                                   \n",
       "precision_score                                                1.0                                                                   \n",
       "support                                                        8.0                                                                   \n",
       "\n",
       "                 What is the total installed capacity from coal?  \\\n",
       "accuracy                                                     1.0   \n",
       "f1_score                                                     1.0   \n",
       "recall_score                                                 1.0   \n",
       "precision_score                                              1.0   \n",
       "support                                                      2.0   \n",
       "\n",
       "                 What is the total volume of crude oil liquid production?  \\\n",
       "accuracy                                                       1.0          \n",
       "f1_score                                                       1.0          \n",
       "recall_score                                                   1.0          \n",
       "precision_score                                                1.0          \n",
       "support                                                        1.0          \n",
       "\n",
       "                 What is the total volume of hydrocarbons production?  \\\n",
       "accuracy                                                       1.0      \n",
       "f1_score                                                       1.0      \n",
       "recall_score                                                   1.0      \n",
       "precision_score                                                1.0      \n",
       "support                                                       28.0      \n",
       "\n",
       "                 What is the total volume of natural gas liquid production?  \\\n",
       "accuracy                                                       1.0            \n",
       "f1_score                                                       1.0            \n",
       "recall_score                                                   1.0            \n",
       "precision_score                                                1.0            \n",
       "support                                                        4.0            \n",
       "\n",
       "                 What is the total volume of natural gas production?  \\\n",
       "accuracy                                                       1.0     \n",
       "f1_score                                                       1.0     \n",
       "recall_score                                                   1.0     \n",
       "precision_score                                                1.0     \n",
       "support                                                       13.0     \n",
       "\n",
       "                 What is the total volume of proven and probable hydrocarbons reserves?  \\\n",
       "accuracy                                                       1.0                        \n",
       "f1_score                                                       1.0                        \n",
       "recall_score                                                   1.0                        \n",
       "precision_score                                                1.0                        \n",
       "support                                                       21.0                        \n",
       "\n",
       "                 What is the volume of estimated proven hydrocarbons reserves?  \n",
       "accuracy                                                       1.0              \n",
       "f1_score                                                       1.0              \n",
       "recall_score                                                   1.0              \n",
       "precision_score                                                1.0              \n",
       "support                                                       20.0              "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kpi wise performance metrics\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results locally\n",
    "if not os.getenv(\"AUTOMATION\"):\n",
    "    scores_df.to_csv(file_config.model_performance_metrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"AUTOMATION\"):\n",
    "    # upload the extracted files to s3\n",
    "    s3c.upload_file_to_s3(\n",
    "        file_config.train_filename,\n",
    "        config.BASE_TRAIN_TEST_DATASET_S3_PREFIX,\n",
    "        \"rel_train_split.csv\"\n",
    "    )\n",
    "    s3c.upload_file_to_s3(\n",
    "        file_config.dev_filename,\n",
    "        config.BASE_TRAIN_TEST_DATASET_S3_PREFIX,\n",
    "        \"rel_test_split.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to s3\n",
    "\n",
    "Great, we have a fine tuned model at this point. We will now save this model as well as its performance metrics to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'CET4PGRKP6SKEMMM',\n",
       "  'HostId': 'pZOSuLYNLXzheNMBZCMH+fiiDhCYxQNCFCB2GOpVqkncEXYh1nnjlraOnKwsvHv5EtbWgBLRCMo=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'pZOSuLYNLXzheNMBZCMH+fiiDhCYxQNCFCB2GOpVqkncEXYh1nnjlraOnKwsvHv5EtbWgBLRCMo=',\n",
       "   'x-amz-request-id': 'CET4PGRKP6SKEMMM',\n",
       "   'date': 'Wed, 13 Jul 2022 16:09:08 GMT',\n",
       "   'etag': '\"3ab74db546b026fac40d8dde1f078ca2\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"3ab74db546b026fac40d8dde1f078ca2\"'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload performance files to s3\n",
    "s3c.upload_df_to_s3(\n",
    "    scores_df,\n",
    "    s3_prefix=config.BASE_SAVED_MODELS_S3_PREFIX,\n",
    "    s3_key=\"relevance_scores.csv\",\n",
    "    filetype=S3FileType.CSV,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = BytesIO()\n",
    "with zipfile.ZipFile(buffer, 'a') as z:\n",
    "    for dirname, _, files in os.walk(file_config.saved_models_dir):\n",
    "        for f in files:\n",
    "            f_path = os.path.join(dirname, f)\n",
    "            with open (f_path, 'rb') as file_content:\n",
    "                z.writestr(f\"RELEVANCE/{f}\", file_content.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'KJ4971ZTBB0PYN26',\n",
       "  'HostId': 'uu3MbfW0G78Ba32m/8qcFuABPkWZpAp9n8SsF057wmAb0usaBskB89epBmuYGbjOFPjO4biGIbw=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'uu3MbfW0G78Ba32m/8qcFuABPkWZpAp9n8SsF057wmAb0usaBskB89epBmuYGbjOFPjO4biGIbw=',\n",
       "   'x-amz-request-id': 'KJ4971ZTBB0PYN26',\n",
       "   'date': 'Wed, 13 Jul 2022 16:09:10 GMT',\n",
       "   'etag': '\"0e5f4b5fd9e45485af9c40bc4167840a\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"0e5f4b5fd9e45485af9c40bc4167840a\"'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.seek(0)\n",
    "# upload model to s3\n",
    "s3c._upload_bytes(\n",
    "    buffer_bytes=buffer,\n",
    "    prefix=config.BASE_SAVED_MODELS_S3_PREFIX,\n",
    "    key=\"RELEVANCE.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we developed a model that can be used for finding relevant paragraphs for a KPI question, given a list of paragraphs from climate report PDFs. With this model in place, we can go ahead to training the kpi extraction model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
